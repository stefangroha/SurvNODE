{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "random_seed = 137\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping class from https://github.com/Bjarten/early-stopping-pytorch\n",
    "from SurvNODE.EarlyStopping import EarlyStopping\n",
    "from SurvNODE.SurvNODE_x_sepnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(odesurv,initial,x,Tstart,Tstop,From,To,trans,status, multiplier=1.,points=500):\n",
    "    with torch.no_grad():\n",
    "        time_grid = np.linspace(0, multiplier, points)\n",
    "        pvec = torch.zeros((points,x.shape[0]))\n",
    "        surv_ode = odesurv.predict(x,torch.from_numpy(np.linspace(0,multiplier,points)).float().to(x.device))\n",
    "        pvec = torch.einsum(\"ilkj,k->ilj\",(surv_ode[:,:,:,:],initial))[:,:,0].cpu()\n",
    "        pvec = np.array(pvec.cpu().detach())\n",
    "        surv_ode_df = pd.DataFrame(pvec)\n",
    "        surv_ode_df.loc[:,\"time\"] = np.linspace(0,multiplier,points)\n",
    "        surv_ode_df = surv_ode_df.set_index([\"time\"])\n",
    "        ev_ode = EvalSurv(surv_ode_df, np.array(Tstop.cpu()), np.array(status.cpu()), censor_surv='km')\n",
    "        conc = ev_ode.concordance_td('antolini')\n",
    "        ibs = ev_ode.integrated_brier_score(time_grid)\n",
    "        inbll = ev_ode.integrated_nbll(time_grid)\n",
    "    return conc,ibs,inbll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "import pandas as pd\n",
    "\n",
    "def make_dataloader(df,Tmax,batchsize):\n",
    "#     cols_standardize = ['x0', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13']\n",
    "#     cols_leave = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6']\n",
    "\n",
    "#     standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "#     leave = [(col, None) for col in cols_leave]\n",
    "#     x_mapper = DataFrameMapper(standardize + leave)\n",
    "#     X = x_mapper.fit_transform(df).astype('float32')\n",
    "\n",
    "    X = df[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']].values\n",
    "    \n",
    "    X = torch.from_numpy(X).float().to(device)\n",
    "    T = torch.from_numpy(df[[\"duration\"]].values).float().flatten().to(device)\n",
    "    T = T/Tmax\n",
    "    T[T==0] = 1e-8\n",
    "    E = torch.from_numpy(df[[\"event\"]].values).float().flatten().to(device)\n",
    "\n",
    "    Tstart = torch.from_numpy(np.array([0 for i in range(T.shape[0])])).float().to(device)\n",
    "    From = torch.tensor([1],device=device).repeat((T.shape))\n",
    "    To = torch.tensor([2],device=device).repeat((T.shape))\n",
    "    trans = torch.tensor([1],device=device).repeat((T.shape))\n",
    "\n",
    "    dataset = TensorDataset(X,Tstart,T,From,To,trans,E)\n",
    "    loader = DataLoader(dataset, batch_size=batchsize, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def odesurv_manual_benchmark(df_train, df_test,config,name):\n",
    "    torch.cuda.empty_cache()\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.loc[:,\"event\"])\n",
    "    \n",
    "    Tmax = df_train[\"duration\"].max()\n",
    "    \n",
    "    train_loader = make_dataloader(df_train,Tmax/config[\"multiplier\"],int(len(df_train)*config[\"batch_size\"]))\n",
    "    val_loader = make_dataloader(df_val,Tmax/config[\"multiplier\"],len(df_val))\n",
    "    test_loader = make_dataloader(df_test,Tmax/config[\"multiplier\"],len(df_test))\n",
    "    \n",
    "    num_in = 9\n",
    "    num_latent = config[\"num_latent\"]\n",
    "    layers_encoder =  [config[\"encoder_neurons\"]]*config[\"num_encoder_layers\"]\n",
    "    dropout_encoder = [config[\"encoder_dropout\"]]*config[\"num_encoder_layers\"]\n",
    "    layers_odefunc1 =  [config[\"odefunc_neurons1\"]]*config[\"num_odefunc_layers1\"]\n",
    "    layers_odefunc2 =  [config[\"odefunc_neurons2\"]]*config[\"num_odefunc_layers2\"]\n",
    "\n",
    "    trans_matrix = torch.tensor([[np.nan,1],[np.nan,np.nan]]).to(device)\n",
    "\n",
    "    encoder = Encoder(num_in,num_latent,layers_encoder, dropout_encoder).to(device)\n",
    "    odefunc = ODEFunc(trans_matrix,num_in,num_latent,layers_odefunc1,layers_odefunc2,config[\"softplus_beta\"]).to(device)\n",
    "    block = ODEBlock(odefunc).to(device)\n",
    "    odesurv = SurvNODE(block,encoder).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(odesurv.parameters(), weight_decay = config[\"weight_decay\"], lr=config[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=config[\"scheduler_gamma\"], patience=config[\"scheduler_epoch\"])\n",
    "\n",
    "    early_stopping = EarlyStopping(name=name,patience=config[\"patience\"], verbose=True)\n",
    "    for i in tqdm(range(1000)):\n",
    "        odesurv.train()\n",
    "        for mini,ds in enumerate(train_loader):\n",
    "            myloss,_,_ = loss(odesurv,*ds,mu=config[\"mu\"])\n",
    "            optimizer.zero_grad()\n",
    "            myloss.backward()    \n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        odesurv.eval()\n",
    "        with torch.no_grad():\n",
    "            lossval,conc,ibs,ibnll = 0., 0., 0., 0.\n",
    "            for _,ds in enumerate(val_loader):\n",
    "                t1,_,_ = loss(odesurv,*ds,mu=config[\"mu\"])\n",
    "                lossval += t1.item()\n",
    "                t1,t2,t3 = measures(odesurv,torch.tensor([1.,0.],device=device),*ds,multiplier=config[\"multiplier\"])\n",
    "                conc += t1\n",
    "                ibs += t2\n",
    "                ibnll += t3\n",
    "            early_stopping(lossval/len(val_loader), odesurv)\n",
    "            scheduler.step(lossval/len(val_loader))\n",
    "            \n",
    "            conc_test,ibs_test,ibnll_test = 0., 0., 0.\n",
    "            print(\"it: \"+str(i)+\", train loss=\"+str(myloss.item())+\", validation loss=\"+str(lossval/len(val_loader))+\", c=\"+str(conc/len(val_loader))+\", ibs=\"+str(ibs/len(val_loader))+\", ibnll=\"+str(ibnll/len(val_loader)))\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    odesurv.load_state_dict(torch.load(name+'_checkpoint.pt'))\n",
    "\n",
    "    odesurv.eval()\n",
    "    with torch.no_grad():\n",
    "        conc,ibs,ibnll = 0., 0., 0.\n",
    "        for _,ds in enumerate(test_loader):\n",
    "            t1,t2,t3 = measures(odesurv,torch.tensor([1.,0.],device=device),*ds,multiplier=config[\"multiplier\"])\n",
    "            conc += t1\n",
    "            ibs += t2\n",
    "            ibnll += t3\n",
    "    return lossval/len(val_loader), conc/len(test_loader), ibs/len(test_loader), ibnll/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36983d29717048b0868127a357052e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-f31874d04a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mconc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mibs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mibnll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0modesurv_manual_benchmark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"metabric_test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0modesurv_bench_vals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mibnll\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-bb15f36fda25>\u001b[0m in \u001b[0;36modesurv_manual_benchmark\u001b[0;34m(df_train, df_test, config, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmyloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0modesurv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmyloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pycox import datasets\n",
    "\n",
    "kfold = StratifiedKFold(5, shuffle=True)\n",
    "df_all = datasets.metabric.read_df()\n",
    "gen = kfold.split(df_all.iloc[:,df_all.columns.values!=\"event\"],df_all.loc[:,\"event\"])\n",
    "\n",
    "config = {\n",
    "    \"lr\": 5e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"num_latent\": 200,\n",
    "    \"encoder_neurons\": 200,\n",
    "    \"num_encoder_layers\": 2,\n",
    "    \"encoder_dropout\": 0.,\n",
    "    \"odefunc_neurons1\": 1000,\n",
    "    \"num_odefunc_layers1\": 3,\n",
    "    \"odefunc_neurons2\": 1000,\n",
    "    \"num_odefunc_layers2\": 3,\n",
    "    \"batch_size\": 1/3,\n",
    "    \"multiplier\": 1.,\n",
    "    \"mu\": 1e-4,\n",
    "    \"softplus_beta\": 1.,\n",
    "    \"scheduler_epoch\": 5,\n",
    "    \"scheduler_gamma\": 0.1,\n",
    "    \"patience\": 20\n",
    "}\n",
    "\n",
    "odesurv_bench_vals = []\n",
    "for g in gen:\n",
    "    df_train = df_all.iloc[g[0]]\n",
    "    df_test =  df_all.iloc[g[1]]\n",
    "    conc, ibs, ibnll = odesurv_manual_benchmark(df_train,df_test,config,\"metabric_test\")\n",
    "    odesurv_bench_vals.append([conc,ibs,ibnll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c=0.6409015344596731+-0.04692738258148167\n",
      "ibs=0.16260818148631234+-0.010486489849482484\n",
      "ibnll=0.4873410756000446+-0.02808576493539076\n"
     ]
    }
   ],
   "source": [
    "print(\"c=\"+str(np.mean(np.array(odesurv_bench_vals)[:,0]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,0])))\n",
    "print(\"ibs=\"+str(np.mean(np.array(odesurv_bench_vals)[:,1]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,1])))\n",
    "print(\"ibnll=\"+str(np.mean(np.array(odesurv_bench_vals)[:,2]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odesurv_bench_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ed95521f494cfe9046bc18f6ad1037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.308389).  Saving model ...\n",
      "it: 0, train loss=0.3627825975418091, validation loss=0.30838891863822937, c=0.47419365009301007, ibs=0.18561537486190832, ibnll=0.5494290075757851\n",
      "Validation loss decreased (0.308389 --> 0.290681).  Saving model ...\n",
      "it: 1, train loss=0.2873215079307556, validation loss=0.29068130254745483, c=0.562379796323738, ibs=0.17089219090813973, ibnll=0.5136373003772895\n",
      "Validation loss decreased (0.290681 --> 0.286903).  Saving model ...\n",
      "it: 2, train loss=0.28436478972435, validation loss=0.2869032025337219, c=0.5320175300312135, ibs=0.17096519199344704, ibnll=0.5147577613136745\n",
      "Validation loss decreased (0.286903 --> 0.284641).  Saving model ...\n",
      "it: 3, train loss=0.3154808282852173, validation loss=0.2846408784389496, c=0.5595106725100104, ibs=0.17261255066958203, ibnll=0.5198031030113369\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 4, train loss=0.2859744727611542, validation loss=0.2853977382183075, c=0.5517545795630103, ibs=0.1727947084764076, ibnll=0.5202443503538257\n",
      "Validation loss decreased (0.284641 --> 0.284447).  Saving model ...\n",
      "it: 5, train loss=0.2819342613220215, validation loss=0.28444650769233704, c=0.5539300690481446, ibs=0.17171004554848826, ibnll=0.5173105937380119\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 6, train loss=0.2717468738555908, validation loss=0.2857497036457062, c=0.49386764195857114, ibs=0.17280446015184406, ibnll=0.5201301680441814\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 7, train loss=0.24345798790454865, validation loss=0.28453338146209717, c=0.5279818393921241, ibs=0.17154053619148518, ibnll=0.5167849033378573\n",
      "Validation loss decreased (0.284447 --> 0.284396).  Saving model ...\n",
      "it: 8, train loss=0.25876352190971375, validation loss=0.284395694732666, c=0.5660056121322949, ibs=0.17146914763981, ibnll=0.5165549304273784\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 9, train loss=0.26973262429237366, validation loss=0.28447026014328003, c=0.5771668190560267, ibs=0.17245831937000847, ibnll=0.5192837178890792\n",
      "Validation loss decreased (0.284396 --> 0.282667).  Saving model ...\n",
      "it: 10, train loss=0.3256281018257141, validation loss=0.28266745805740356, c=0.5644606993095186, ibs=0.17119817462896533, ibnll=0.5160055867425957\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 11, train loss=0.2887221872806549, validation loss=0.2841411530971527, c=0.5364315666677176, ibs=0.17269023362420713, ibnll=0.519949151892619\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 12, train loss=0.26156681776046753, validation loss=0.284074604511261, c=0.5240407352523883, ibs=0.17038059021048316, ibnll=0.5132948833412511\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 13, train loss=0.2895869314670563, validation loss=0.2836794853210449, c=0.5491692152473437, ibs=0.1721453438945172, ibnll=0.5185508466004687\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 14, train loss=0.32611027359962463, validation loss=0.2839702367782593, c=0.5608664123340795, ibs=0.17269413226479088, ibnll=0.5199891612218834\n",
      "EarlyStopping counter: 5 out of 20                     \n",
      "it: 15, train loss=0.28782325983047485, validation loss=0.2846032381057739, c=0.5350127691774127, ibs=0.17245063963843493, ibnll=0.5192749839101614\n",
      "EarlyStopping counter: 6 out of 20                     \n",
      "it: 16, train loss=0.2567444443702698, validation loss=0.2830658555030823, c=0.5905981019642463, ibs=0.17151920727124684, ibnll=0.5168482059958778\n",
      "Validation loss decreased (0.282667 --> 0.281263).  Saving model ...\n",
      "it: 17, train loss=0.2691355347633362, validation loss=0.2812625467777252, c=0.5921114859539048, ibs=0.17135507182592014, ibnll=0.5166352336227957\n",
      "Validation loss decreased (0.281263 --> 0.279560).  Saving model ...\n",
      "it: 18, train loss=0.29277098178863525, validation loss=0.2795601189136505, c=0.5792161932086893, ibs=0.17022633447508773, ibnll=0.513586717924551\n",
      "Validation loss decreased (0.279560 --> 0.278400).  Saving model ...\n",
      "it: 19, train loss=0.24582257866859436, validation loss=0.27840033173561096, c=0.5740769934104739, ibs=0.17016695303386795, ibnll=0.5135669493673222\n",
      "Validation loss decreased (0.278400 --> 0.275521).  Saving model ...\n",
      "it: 20, train loss=0.2717120945453644, validation loss=0.2755206525325775, c=0.5822429611880064, ibs=0.16975650791948171, ibnll=0.5127947475420064\n",
      "Validation loss decreased (0.275521 --> 0.274321).  Saving model ...\n",
      "it: 21, train loss=0.27624669671058655, validation loss=0.2743209898471832, c=0.5780496263833276, ibs=0.1700301842515546, ibnll=0.513729998525533\n",
      "Validation loss decreased (0.274321 --> 0.273561).  Saving model ...\n",
      "it: 22, train loss=0.2846045196056366, validation loss=0.2735609710216522, c=0.5832834126808967, ibs=0.16849434596813054, ibnll=0.509473852824141\n",
      "Validation loss decreased (0.273561 --> 0.271011).  Saving model ...\n",
      "it: 23, train loss=0.2813279628753662, validation loss=0.27101096510887146, c=0.5843553930069049, ibs=0.1681991645344531, ibnll=0.5090742575868074\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 24, train loss=0.2767973244190216, validation loss=0.2725166082382202, c=0.5812025096951162, ibs=0.16935808949381312, ibnll=0.5120616501200963\n",
      "Validation loss decreased (0.271011 --> 0.270253).  Saving model ...\n",
      "it: 25, train loss=0.3010478913784027, validation loss=0.27025333046913147, c=0.5839139893432544, ibs=0.16746432111476603, ibnll=0.5069827721457122\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 26, train loss=0.231342613697052, validation loss=0.27056774497032166, c=0.5753066179020715, ibs=0.16834745223171343, ibnll=0.5093107009898152\n",
      "Validation loss decreased (0.270253 --> 0.267280).  Saving model ...\n",
      "it: 27, train loss=0.24500672519207, validation loss=0.2672795057296753, c=0.5746445124065959, ibs=0.16749259642572403, ibnll=0.506928419081541\n",
      "Validation loss decreased (0.267280 --> 0.267179).  Saving model ...\n",
      "it: 28, train loss=0.2712244987487793, validation loss=0.26717889308929443, c=0.5713339849292177, ibs=0.16671228150800757, ibnll=0.5049090569745533\n",
      "Validation loss decreased (0.267179 --> 0.261964).  Saving model ...\n",
      "it: 29, train loss=0.29432910680770874, validation loss=0.26196393370628357, c=0.5818961440237097, ibs=0.166506186512971, ibnll=0.5048339094629168\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 30, train loss=0.2552853524684906, validation loss=0.26240473985671997, c=0.5808556925308195, ibs=0.16635960672744976, ibnll=0.504384643489042\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 31, train loss=0.3049792945384979, validation loss=0.26397645473480225, c=0.5771983478891446, ibs=0.16524146067857728, ibnll=0.5007614196731947\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 32, train loss=0.2509196698665619, validation loss=0.26532334089279175, c=0.5764101270611974, ibs=0.16676938351052867, ibnll=0.5055415740972865\n",
      "Validation loss decreased (0.261964 --> 0.261038).  Saving model ...\n",
      "it: 33, train loss=0.2896875739097595, validation loss=0.26103833317756653, c=0.5787432607119211, ibs=0.16621481518476233, ibnll=0.5039996326232761\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 34, train loss=0.2416333258152008, validation loss=0.2690865397453308, c=0.5510609452344168, ibs=0.166490619366888, ibnll=0.504302612495892\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 35, train loss=0.23524464666843414, validation loss=0.2672509551048279, c=0.576536242393669, ibs=0.1657791824297732, ibnll=0.5019985046908662\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 36, train loss=0.30105817317962646, validation loss=0.27407506108283997, c=0.5867831131569821, ibs=0.1707187760852536, ibnll=0.5156242258444723\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 37, train loss=0.2601683437824249, validation loss=0.2716902792453766, c=0.5683387457830186, ibs=0.16955331696954482, ibnll=0.5125722227196747\n",
      "EarlyStopping counter: 5 out of 20                     \n",
      "it: 38, train loss=0.2790619730949402, validation loss=0.2700437605381012, c=0.5602358356717217, ibs=0.16814856705932818, ibnll=0.5086677213295314\n",
      "EarlyStopping counter: 6 out of 20                     \n",
      "it: 39, train loss=0.2901899218559265, validation loss=0.26419129967689514, c=0.5552542800390957, ibs=0.16572612086995583, ibnll=0.5018553561139891\n",
      "EarlyStopping counter: 7 out of 20                     \n",
      "it: 40, train loss=0.26303815841674805, validation loss=0.26117387413978577, c=0.554339943878677, ibs=0.1649618658337987, ibnll=0.4997428835743742\n",
      "EarlyStopping counter: 8 out of 20                     \n",
      "it: 41, train loss=0.2601139545440674, validation loss=0.2612621784210205, c=0.5638616514802787, ibs=0.16478105023300252, ibnll=0.4989377851885912\n",
      "Validation loss decreased (0.261038 --> 0.259154).  Saving model ...\n",
      "it: 42, train loss=0.24560511112213135, validation loss=0.25915440917015076, c=0.567392880789482, ibs=0.16478115473447436, ibnll=0.499285714097499\n",
      "Validation loss decreased (0.259154 --> 0.257043).  Saving model ...\n",
      "it: 43, train loss=0.24182231724262238, validation loss=0.25704315304756165, c=0.5668884194595958, ibs=0.16501160832434092, ibnll=0.5005094296220756\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 44, train loss=0.31903311610221863, validation loss=0.2576794922351837, c=0.5631364883185673, ibs=0.16498787314264265, ibnll=0.500312481582743\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 45, train loss=0.287494033575058, validation loss=0.2578684985637665, c=0.5622536809912665, ibs=0.16530882094169846, ibnll=0.5012431427393732\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 46, train loss=0.2710232436656952, validation loss=0.257809042930603, c=0.5611501718321404, ibs=0.16582562056461603, ibnll=0.5028549588960551\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 47, train loss=0.2914399802684784, validation loss=0.25797122716903687, c=0.5682441592836649, ibs=0.16577804537357452, ibnll=0.502594466407016\n",
      "EarlyStopping counter: 5 out of 20                     \n",
      "it: 48, train loss=0.2739153206348419, validation loss=0.25792232155799866, c=0.5669199482927136, ibs=0.16585744165417993, ibnll=0.5028176851701297\n",
      "Validation loss decreased (0.257043 --> 0.256914).  Saving model ...\n",
      "it: 49, train loss=0.22699379920959473, validation loss=0.25691354274749756, c=0.5690323801116121, ibs=0.16603962065493946, ibnll=0.5034417432283043\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 50, train loss=0.26468244194984436, validation loss=0.25706180930137634, c=0.5724374940883438, ibs=0.16574187361787385, ibnll=0.5025819595177198\n",
      "Validation loss decreased (0.256914 --> 0.256829).  Saving model ...\n",
      "it: 51, train loss=0.24649183452129364, validation loss=0.2568286955356598, c=0.5685909764479616, ibs=0.16551847519003315, ibnll=0.5018813813602566\n",
      "Validation loss decreased (0.256829 --> 0.255566).  Saving model ...\n",
      "it: 52, train loss=0.25441205501556396, validation loss=0.25556617975234985, c=0.5695683702746162, ibs=0.16527732440836973, ibnll=0.5012012539941734\n",
      "Validation loss decreased (0.255566 --> 0.254688).  Saving model ...\n",
      "it: 53, train loss=0.26238641142845154, validation loss=0.2546882927417755, c=0.5719960904246933, ibs=0.1649859247408244, ibnll=0.5004237515713169\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 54, train loss=0.2585428059101105, validation loss=0.25479286909103394, c=0.573477945581234, ibs=0.16478121893401046, ibnll=0.499811212799796\n",
      "Validation loss decreased (0.254688 --> 0.254582).  Saving model ...\n",
      "it: 55, train loss=0.2587669789791107, validation loss=0.2545819878578186, c=0.5710186965980389, ibs=0.1650226694943416, ibnll=0.5005077836718224\n",
      "Validation loss decreased (0.254582 --> 0.254430).  Saving model ...\n",
      "it: 56, train loss=0.2404622733592987, validation loss=0.2544300854206085, c=0.5707664659330958, ibs=0.16457443156405419, ibnll=0.49910941107812806\n",
      "Validation loss decreased (0.254430 --> 0.253805).  Saving model ...\n",
      "it: 57, train loss=0.2197386473417282, validation loss=0.25380492210388184, c=0.5734464167481161, ibs=0.1645566623157342, ibnll=0.49911969086140345\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 58, train loss=0.2718501389026642, validation loss=0.2541726231575012, c=0.5678342844531324, ibs=0.16456178618682477, ibnll=0.49909865006858084\n",
      "Validation loss decreased (0.253805 --> 0.253292).  Saving model ...\n",
      "it: 59, train loss=0.25419285893440247, validation loss=0.25329217314720154, c=0.5705457641012706, ibs=0.1644652246541752, ibnll=0.498867077219398\n",
      "Validation loss decreased (0.253292 --> 0.252718).  Saving model ...\n",
      "it: 60, train loss=0.22515007853507996, validation loss=0.25271832942962646, c=0.5748652142384211, ibs=0.16461414610628392, ibnll=0.499318531563073\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 61, train loss=0.2631131112575531, validation loss=0.25302305817604065, c=0.5705457641012706, ibs=0.16444908514752107, ibnll=0.49876488831814225\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 62, train loss=0.2581063508987427, validation loss=0.25316041707992554, c=0.568496389948608, ibs=0.16440425991386778, ibnll=0.4986155930339638\n",
      "Validation loss decreased (0.252718 --> 0.252263).  Saving model ...\n",
      "it: 63, train loss=0.24733158946037292, validation loss=0.25226283073425293, c=0.572090676924047, ibs=0.16454049186140482, ibnll=0.4990797562366888\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 64, train loss=0.26510125398635864, validation loss=0.2529646158218384, c=0.5731626572500552, ibs=0.16430995975476564, ibnll=0.498318822396703\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 65, train loss=0.25457310676574707, validation loss=0.2532353699207306, c=0.5707034082668601, ibs=0.1642067322460722, ibnll=0.49794326471149863\n",
      "Validation loss decreased (0.252263 --> 0.251111).  Saving model ...\n",
      "it: 66, train loss=0.2373904138803482, validation loss=0.25111061334609985, c=0.5729734842513479, ibs=0.16469095032465067, ibnll=0.49952726459418695\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 67, train loss=0.22978992760181427, validation loss=0.25130563974380493, c=0.5764416558943154, ibs=0.1644245671025975, ibnll=0.4987004659823339\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 68, train loss=0.26821714639663696, validation loss=0.25269967317581177, c=0.5770407037235552, ibs=0.16392814021316301, ibnll=0.4970435601231108\n",
      "Validation loss decreased (0.251111 --> 0.251033).  Saving model ...\n",
      "it: 69, train loss=0.23190975189208984, validation loss=0.25103291869163513, c=0.5705142352681527, ibs=0.16425616785725178, ibnll=0.49826437670984197\n",
      "Validation loss decreased (0.251033 --> 0.250977).  Saving model ...\n",
      "it: 70, train loss=0.26780039072036743, validation loss=0.2509770095348358, c=0.5744868682410064, ibs=0.16441693066865315, ibnll=0.4987801959603831\n",
      "Validation loss decreased (0.250977 --> 0.250952).  Saving model ...\n",
      "it: 71, train loss=0.2543639540672302, validation loss=0.2509517967700958, c=0.5699151874389129, ibs=0.16400361283534043, ibnll=0.4974942214098883\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 72, train loss=0.23475392162799835, validation loss=0.2510764002799988, c=0.5740769934104739, ibs=0.16379989169638856, ibnll=0.49673951645380676\n",
      "Validation loss decreased (0.250952 --> 0.249484).  Saving model ...\n",
      "it: 73, train loss=0.24561724066734314, validation loss=0.2494840770959854, c=0.5810448655295267, ibs=0.16421097766443588, ibnll=0.4980807498612904\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 74, train loss=0.24885495007038116, validation loss=0.24955454468727112, c=0.5710502254311568, ibs=0.16403070438896758, ibnll=0.49752670257378057\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 75, train loss=0.23836590349674225, validation loss=0.24994081258773804, c=0.5742346375760633, ibs=0.16379108267161308, ibnll=0.49676525553516054\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 76, train loss=0.2643142342567444, validation loss=0.25158417224884033, c=0.5706718794337422, ibs=0.1635414591630988, ibnll=0.49579795451800623\n",
      "Validation loss decreased (0.249484 --> 0.248981).  Saving model ...\n",
      "it: 77, train loss=0.2486104518175125, validation loss=0.24898141622543335, c=0.5746445124065959, ibs=0.16383092322819534, ibnll=0.49694609743295814\n",
      "Validation loss decreased (0.248981 --> 0.248416).  Saving model ...\n",
      "it: 78, train loss=0.24485108256340027, validation loss=0.24841554462909698, c=0.5758110792319576, ibs=0.16411720544007494, ibnll=0.4977779766848548\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 79, train loss=0.248234361410141, validation loss=0.24933244287967682, c=0.5786802030456852, ibs=0.16379475585990705, ibnll=0.4966900624846764\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 80, train loss=0.2337360680103302, validation loss=0.2492736428976059, c=0.5755273197338967, ibs=0.16376937302736402, ibnll=0.49660473997478005\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 81, train loss=0.2647738456726074, validation loss=0.248661071062088, c=0.5742031087429454, ibs=0.16363524671205482, ibnll=0.4962804634881375\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 82, train loss=0.24275930225849152, validation loss=0.24862420558929443, c=0.577923511050856, ibs=0.16358655373598718, ibnll=0.49613503344545895\n",
      "Validation loss decreased (0.248416 --> 0.248371).  Saving model ...\n",
      "it: 83, train loss=0.24066177010536194, validation loss=0.24837127327919006, c=0.5742976952422991, ibs=0.16368916443582643, ibnll=0.4964190824918447\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 84, train loss=0.24524350464344025, validation loss=0.24902667105197906, c=0.5723429075889901, ibs=0.1635225038511762, ibnll=0.4957915561082563\n",
      "Validation loss decreased (0.248371 --> 0.247840).  Saving model ...\n",
      "it: 85, train loss=0.26296138763427734, validation loss=0.24784035980701447, c=0.5736355897468235, ibs=0.1636535324361987, ibnll=0.49625509596297124\n",
      "Validation loss decreased (0.247840 --> 0.246832).  Saving model ...\n",
      "it: 86, train loss=0.24144290387630463, validation loss=0.24683238565921783, c=0.5742976952422991, ibs=0.1637313800773335, ibnll=0.49654811768175194\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 87, train loss=0.24323144555091858, validation loss=0.2486323118209839, c=0.5770091748904373, ibs=0.16317470767675255, ibnll=0.494685831354457\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 88, train loss=0.2341655194759369, validation loss=0.24819505214691162, c=0.5725636094208153, ibs=0.16334009636450747, ibnll=0.4951911926995899\n",
      "Validation loss decreased (0.246832 --> 0.246433).  Saving model ...\n",
      "it: 89, train loss=0.2521817982196808, validation loss=0.24643275141716003, c=0.5769145883910837, ibs=0.1637649664328903, ibnll=0.4966041590783792\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 90, train loss=0.2526647448539734, validation loss=0.24727262556552887, c=0.5754957909007787, ibs=0.16327930462085424, ibnll=0.4950791563162115\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 91, train loss=0.28254497051239014, validation loss=0.24766889214515686, c=0.5759371945644292, ibs=0.16311628051880048, ibnll=0.49451927829085573\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 92, train loss=0.2605607211589813, validation loss=0.24677430093288422, c=0.5719645615915755, ibs=0.16325329596734392, ibnll=0.4950007729729463\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 93, train loss=0.25895577669143677, validation loss=0.2468443512916565, c=0.5760633098969007, ibs=0.1633622167507495, ibnll=0.49523494808038515\n",
      "Validation loss decreased (0.246433 --> 0.246405).  Saving model ...\n",
      "it: 94, train loss=0.27349671721458435, validation loss=0.24640494585037231, c=0.5779550398839739, ibs=0.16332808157202972, ibnll=0.4951910387522758\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 95, train loss=0.23232048749923706, validation loss=0.24658410251140594, c=0.5763470693949617, ibs=0.1632108822727487, ibnll=0.4948177436080041\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 96, train loss=0.20683859288692474, validation loss=0.24644671380519867, c=0.5749913295708926, ibs=0.16314119474671276, ibnll=0.4945842518020515\n",
      "Validation loss decreased (0.246405 --> 0.245959).  Saving model ...\n",
      "it: 97, train loss=0.22106415033340454, validation loss=0.2459588497877121, c=0.5758741368981934, ibs=0.1633886742344026, ibnll=0.4952802026107712\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 98, train loss=0.24612167477607727, validation loss=0.24654504656791687, c=0.5792161932086893, ibs=0.16322130086676395, ibnll=0.4946734858869289\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 99, train loss=0.22976526618003845, validation loss=0.2461773157119751, c=0.576000252230665, ibs=0.16314568417812897, ibnll=0.4945189853752462\n",
      "Validation loss decreased (0.245959 --> 0.245830).  Saving model ...\n",
      "it: 100, train loss=0.22088107466697693, validation loss=0.24583007395267487, c=0.577923511050856, ibs=0.16317556125082702, ibnll=0.49457337766071485\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 101, train loss=0.25541993975639343, validation loss=0.24589918553829193, c=0.5803197023678154, ibs=0.16301090136280874, ibnll=0.49401615189333037\n",
      "Validation loss decreased (0.245830 --> 0.244881).  Saving model ...\n",
      "it: 102, train loss=0.2583940923213959, validation loss=0.24488115310668945, c=0.5779865687170918, ibs=0.1632654372941109, ibnll=0.49487585898452446\n",
      "Validation loss decreased (0.244881 --> 0.244388).  Saving model ...\n",
      "it: 103, train loss=0.21820607781410217, validation loss=0.24438799917697906, c=0.5782703282151528, ibs=0.16315238354925968, ibnll=0.49451991746048\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 104, train loss=0.30117449164390564, validation loss=0.24654507637023926, c=0.5786486742125674, ibs=0.16261076972212268, ibnll=0.49255634921251235\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 105, train loss=0.2581423819065094, validation loss=0.24439947307109833, c=0.5765047135605511, ibs=0.16289652132317442, ibnll=0.4937519531284755\n",
      "Validation loss decreased (0.244388 --> 0.243025).  Saving model ...\n",
      "it: 106, train loss=0.2186575084924698, validation loss=0.24302470684051514, c=0.5747706277390674, ibs=0.16354764324225565, ibnll=0.49585368975206373\n",
      "EarlyStopping counter: 1 out of 20                     \n",
      "it: 107, train loss=0.22366385161876678, validation loss=0.24380281567573547, c=0.5747075700728316, ibs=0.16284414670012645, ibnll=0.4936824284562796\n",
      "EarlyStopping counter: 2 out of 20                     \n",
      "it: 108, train loss=0.23436486721038818, validation loss=0.244519904255867, c=0.575148973736482, ibs=0.16262174574447866, ibnll=0.4928210660153109\n",
      "EarlyStopping counter: 3 out of 20                     \n",
      "it: 109, train loss=0.22846658527851105, validation loss=0.2444985806941986, c=0.5805404041996406, ibs=0.16261844640676407, ibnll=0.4927112579550781\n",
      "EarlyStopping counter: 4 out of 20                     \n",
      "it: 110, train loss=0.24206136167049408, validation loss=0.24365131556987762, c=0.5780180975502097, ibs=0.16280688157332157, ibnll=0.49340501687055355\n",
      "EarlyStopping counter: 5 out of 20                     \n",
      "it: 111, train loss=0.26804274320602417, validation loss=0.2438211888074875, c=0.5767254153923763, ibs=0.1627206983326585, ibnll=0.49306849095868516\n",
      "EarlyStopping counter: 6 out of 20                     \n",
      "it: 112, train loss=0.2515113651752472, validation loss=0.24367724359035492, c=0.5782387993820348, ibs=0.1627197148985856, ibnll=0.4930554769060226\n",
      "EarlyStopping counter: 7 out of 20                     \n",
      "it: 113, train loss=0.22786100208759308, validation loss=0.2436685860157013, c=0.5768830595579657, ibs=0.16273970394657267, ibnll=0.4931085044159129\n",
      "EarlyStopping counter: 8 out of 20                     \n",
      "it: 114, train loss=0.2616478502750397, validation loss=0.24370913207530975, c=0.5768515307248478, ibs=0.16275028185563026, ibnll=0.4931303970753344\n",
      "EarlyStopping counter: 9 out of 20                     \n",
      "it: 115, train loss=0.24507872760295868, validation loss=0.24376733601093292, c=0.5775451650534413, ibs=0.1627532392661768, ibnll=0.4931272747028783\n",
      "EarlyStopping counter: 10 out of 20                    \n",
      "it: 116, train loss=0.25191888213157654, validation loss=0.24383120238780975, c=0.5783018570482706, ibs=0.1627465667901802, ibnll=0.4930958929982438\n",
      "EarlyStopping counter: 11 out of 20                    \n",
      "it: 117, train loss=0.20872174203395844, validation loss=0.24386116862297058, c=0.5809187501970552, ibs=0.16275068205914364, ibnll=0.4931043233295252\n",
      "EarlyStopping counter: 12 out of 20                    \n",
      "it: 118, train loss=0.2468172162771225, validation loss=0.24391819536685944, c=0.5789009048775104, ibs=0.16273694709648284, ibnll=0.4930513340956718\n",
      "EarlyStopping counter: 13 out of 20                    \n",
      "it: 119, train loss=0.2598494291305542, validation loss=0.24391576647758484, c=0.5778604533846202, ibs=0.16273729369406204, ibnll=0.49305262885468976\n",
      "EarlyStopping counter: 14 out of 20                    \n",
      "it: 120, train loss=0.23833617568016052, validation loss=0.2439073622226715, c=0.5797206545385756, ibs=0.16273809892453042, ibnll=0.49305617994791473\n",
      "EarlyStopping counter: 15 out of 20                    \n",
      "it: 121, train loss=0.19966261088848114, validation loss=0.2439037710428238, c=0.5803197023678154, ibs=0.16273931687310894, ibnll=0.49306039929302264\n",
      "EarlyStopping counter: 16 out of 20                    \n",
      "it: 122, train loss=0.22812071442604065, validation loss=0.24389542639255524, c=0.5781757417157991, ibs=0.162739911586577, ibnll=0.49306371357964623\n",
      "EarlyStopping counter: 17 out of 20                    \n",
      "it: 123, train loss=0.22766217589378357, validation loss=0.2438891977071762, c=0.5772929343884983, ibs=0.16273928900433215, ibnll=0.4930628752737267\n",
      "EarlyStopping counter: 18 out of 20                    \n",
      "it: 124, train loss=0.23568955063819885, validation loss=0.2438843548297882, c=0.5767884730586121, ibs=0.1627398753900355, ibnll=0.4930652699123713\n",
      "EarlyStopping counter: 19 out of 20                    \n",
      "it: 125, train loss=0.2263471484184265, validation loss=0.24388419091701508, c=0.5778919822177381, ibs=0.1627398432863925, ibnll=0.49306520543556387\n",
      "EarlyStopping counter: 20 out of 20                    \n",
      "it: 126, train loss=0.22325968742370605, validation loss=0.24388353526592255, c=0.5783333858813885, ibs=0.1627399077036433, ibnll=0.49306546243929833\n",
      "Early stopping                                         \n",
      "  1%|          | 1/100 [28:08<46:26:16, 1688.65s/trial, best loss: 0.24388353526592255]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0312ec3828174a66be00ff23d4b8e8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.449379).  Saving model ...                        \n",
      "it: 0, train loss=0.444072961807251, validation loss=0.4493785798549652, c=0.41538414278253927, ibs=0.251535327312559, ibnll=0.6931567216709986\n",
      "Validation loss decreased (0.449379 --> 0.437089).  Saving model ...                   \n",
      "it: 1, train loss=0.4375377297401428, validation loss=0.4370894432067871, c=0.45163272202254784, ibs=0.24642078960098, ibnll=0.6816585727867762\n",
      "Validation loss decreased (0.437089 --> 0.423800).  Saving model ...                   \n",
      "it: 2, train loss=0.4299686551094055, validation loss=0.42380020022392273, c=0.5038859705710688, ibs=0.2407520541315941, ibnll=0.6690452610944831\n",
      "Validation loss decreased (0.423800 --> 0.410172).  Saving model ...                   \n",
      "it: 3, train loss=0.39993271231651306, validation loss=0.41017237305641174, c=0.5127330814364267, ibs=0.2347875304024837, ibnll=0.6559099995152446\n",
      "Validation loss decreased (0.410172 --> 0.396480).  Saving model ...                   \n",
      "it: 4, train loss=0.4080203175544739, validation loss=0.3964804410934448, c=0.5351580499493134, ibs=0.228681573739015, ibnll=0.6425843868820664\n",
      "Validation loss decreased (0.396480 --> 0.383212).  Saving model ...                   \n",
      "it: 5, train loss=0.3867776095867157, validation loss=0.38321152329444885, c=0.5865511627192578, ibs=0.22264263368938025, ibnll=0.6295040069668271\n",
      "Validation loss decreased (0.383212 --> 0.370555).  Saving model ...                   \n",
      "it: 6, train loss=0.3592943251132965, validation loss=0.3705552816390991, c=0.6095597947961785, ibs=0.21677558702054553, ibnll=0.6168706040685344\n",
      "Validation loss decreased (0.370555 --> 0.358667).  Saving model ...                   \n",
      "it: 7, train loss=0.3615679442882538, validation loss=0.35866695642471313, c=0.6253187110250975, ibs=0.21116317851229488, ibnll=0.6048313831856741\n",
      "Validation loss decreased (0.358667 --> 0.347865).  Saving model ...                   \n",
      "it: 8, train loss=0.3500894606113434, validation loss=0.3478645086288452, c=0.6296501090529291, ibs=0.20596589449270794, ibnll=0.5937018161338619\n",
      "Validation loss decreased (0.347865 --> 0.338001).  Saving model ...                   \n",
      "it: 9, train loss=0.3419853746891022, validation loss=0.3380005955696106, c=0.62925076029859, ibs=0.20113624457355678, ibnll=0.5833538845567952\n",
      "Validation loss decreased (0.338001 --> 0.329298).  Saving model ...                   \n",
      "it: 10, train loss=0.3522915542125702, validation loss=0.3292984366416931, c=0.6459005314410347, ibs=0.19683793226460114, ibnll=0.5741199552257438\n",
      "Validation loss decreased (0.329298 --> 0.321663).  Saving model ...                   \n",
      "it: 11, train loss=0.34737247228622437, validation loss=0.32166343927383423, c=0.6513070991920867, ibs=0.19306048596003472, ibnll=0.5659685523408239\n",
      "Validation loss decreased (0.321663 --> 0.315070).  Saving model ...                   \n",
      "it: 12, train loss=0.3211019039154053, validation loss=0.3150700628757477, c=0.6514299757318834, ibs=0.189810438731775, ibnll=0.5589148132137473\n",
      "Validation loss decreased (0.315070 --> 0.309284).  Saving model ...                   \n",
      "it: 13, train loss=0.28554338216781616, validation loss=0.3092840313911438, c=0.6527816176696464, ibs=0.1871241342719005, ibnll=0.5530467081904177\n",
      "Validation loss decreased (0.309284 --> 0.303736).  Saving model ...                   \n",
      "it: 14, train loss=0.3228984475135803, validation loss=0.3037359416484833, c=0.6525358645900532, ibs=0.18488137066059437, ibnll=0.5481235831246641\n",
      "Validation loss decreased (0.303736 --> 0.299388).  Saving model ...                   \n",
      "it: 15, train loss=0.3206423819065094, validation loss=0.29938822984695435, c=0.6463305993303229, ibs=0.18302319422092184, ibnll=0.5439580508940769\n",
      "Validation loss decreased (0.299388 --> 0.293188).  Saving model ...                   \n",
      "it: 16, train loss=0.29537639021873474, validation loss=0.29318755865097046, c=0.6476208029981876, ibs=0.18143882375236328, ibnll=0.5404958290263381\n",
      "Validation loss decreased (0.293188 --> 0.289015).  Saving model ...                   \n",
      "it: 17, train loss=0.26971235871315, validation loss=0.2890150249004364, c=0.6535803151783246, ibs=0.1799917814839213, ibnll=0.5371553434253813\n",
      "Validation loss decreased (0.289015 --> 0.284937).  Saving model ...                   \n",
      "it: 18, train loss=0.26535889506340027, validation loss=0.2849368155002594, c=0.6603385248671397, ibs=0.17886731732459923, ibnll=0.5345093152855823\n",
      "Validation loss decreased (0.284937 --> 0.282636).  Saving model ...                   \n",
      "it: 19, train loss=0.2829169034957886, validation loss=0.28263550996780396, c=0.6681719042791755, ibs=0.17816495198169444, ibnll=0.5327394605172141\n",
      "Validation loss decreased (0.282636 --> 0.279049).  Saving model ...                   \n",
      "it: 20, train loss=0.26089751720428467, validation loss=0.2790486514568329, c=0.6734248763554819, ibs=0.1773451838142797, ibnll=0.530638232712153\n",
      "Validation loss decreased (0.279049 --> 0.276573).  Saving model ...                   \n",
      "it: 21, train loss=0.26845765113830566, validation loss=0.276572585105896, c=0.6837772248333487, ibs=0.1762034456172227, ibnll=0.5279385013482316\n",
      "Validation loss decreased (0.276573 --> 0.270891).  Saving model ...                   \n",
      "it: 22, train loss=0.3013955354690552, validation loss=0.2708909213542938, c=0.7014100082941664, ibs=0.17717898382647526, ibnll=0.5303618775276807\n",
      "Validation loss decreased (0.270891 --> 0.267127).  Saving model ...                   \n",
      "it: 23, train loss=0.2624090015888214, validation loss=0.2671266496181488, c=0.6946517986053513, ibs=0.17402534365842248, ibnll=0.5226383542308392\n",
      "Validation loss decreased (0.267127 --> 0.261430).  Saving model ...                   \n",
      "it: 24, train loss=0.2804204821586609, validation loss=0.26142987608909607, c=0.701532884833963, ibs=0.17485013540205635, ibnll=0.5241960488112593\n",
      "Validation loss decreased (0.261430 --> 0.254576).  Saving model ...                   \n",
      "it: 25, train loss=0.2755247950553894, validation loss=0.25457581877708435, c=0.7034989094707093, ibs=0.17219285181481583, ibnll=0.5181202426383876\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 26, train loss=0.2518184185028076, validation loss=0.25715041160583496, c=0.6995361410622677, ibs=0.173355112551989, ibnll=0.5200763014578044\n",
      "Validation loss decreased (0.254576 --> 0.244610).  Saving model ...                   \n",
      "it: 27, train loss=0.23452891409397125, validation loss=0.2446095198392868, c=0.7053113384327098, ibs=0.16854938390007412, ibnll=0.5093540930663448\n",
      "Validation loss decreased (0.244610 --> 0.235166).  Saving model ...                   \n",
      "it: 28, train loss=0.2615063190460205, validation loss=0.23516565561294556, c=0.7058335637268455, ibs=0.17093784076832583, ibnll=0.5139063492291458\n",
      "Validation loss decreased (0.235166 --> 0.232461).  Saving model ...                   \n",
      "it: 29, train loss=0.22044499218463898, validation loss=0.23246078193187714, c=0.7064479464258286, ibs=0.1689262144854189, ibnll=0.5089838093685017\n",
      "Validation loss decreased (0.232461 --> 0.224023).  Saving model ...                   \n",
      "it: 30, train loss=0.21836760640144348, validation loss=0.22402308881282806, c=0.7060178785365404, ibs=0.16456386004433074, ibnll=0.4993240424329133\n",
      "Validation loss decreased (0.224023 --> 0.218743).  Saving model ...                   \n",
      "it: 31, train loss=0.20634710788726807, validation loss=0.21874262392520905, c=0.7042976069793875, ibs=0.16715590547615644, ibnll=0.5040817478604223\n",
      "Validation loss decreased (0.218743 --> 0.215694).  Saving model ...                   \n",
      "it: 32, train loss=0.2020639181137085, validation loss=0.21569421887397766, c=0.7106257487789144, ibs=0.16868162904766995, ibnll=0.5069101238040983\n",
      "Validation loss decreased (0.215694 --> 0.204102).  Saving model ...                   \n",
      "it: 33, train loss=0.2044287472963333, validation loss=0.20410209894180298, c=0.7034989094707093, ibs=0.16208838182083446, ibnll=0.49223740102533103\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 34, train loss=0.22579817473888397, validation loss=0.2205493003129959, c=0.6969557337265383, ibs=0.17096969854191255, ibnll=0.5121965206782685\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 35, train loss=0.2041097730398178, validation loss=0.21177256107330322, c=0.7041132921696925, ibs=0.1616110673268509, ibnll=0.49125255082011526\n",
      "Validation loss decreased (0.204102 --> 0.201713).  Saving model ...                   \n",
      "it: 36, train loss=0.20745830237865448, validation loss=0.20171257853507996, c=0.7103185574294227, ibs=0.16454059268841742, ibnll=0.49603869823837854\n",
      "Validation loss decreased (0.201713 --> 0.194302).  Saving model ...                   \n",
      "it: 37, train loss=0.21232973039150238, validation loss=0.19430164992809296, c=0.7041440113046417, ibs=0.16394450434312102, ibnll=0.49655364949512826\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 38, train loss=0.20421384274959564, validation loss=0.2071305811405182, c=0.700365557705895, ibs=0.1694961967710365, ibnll=0.5080564315227957\n",
      "Validation loss decreased (0.194302 --> 0.194128).  Saving model ...                   \n",
      "it: 39, train loss=0.1843648999929428, validation loss=0.19412805140018463, c=0.7056492489171505, ibs=0.15920256176226175, ibnll=0.48319069596056813\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 40, train loss=0.18794329464435577, validation loss=0.23306770622730255, c=0.7077381500936933, ibs=0.18312040342798347, ibnll=0.5381501844315699\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 41, train loss=0.2174920290708542, validation loss=0.1983591616153717, c=0.706325069886032, ibs=0.15895194952985178, ibnll=0.48182700880403595\n",
      "EarlyStopping counter: 3 out of 20                                                     \n",
      "it: 42, train loss=0.17061397433280945, validation loss=0.2229519784450531, c=0.6934537523423341, ibs=0.18282248389081937, ibnll=0.5372635010869647\n",
      "Validation loss decreased (0.194128 --> 0.182156).  Saving model ...                   \n",
      "it: 43, train loss=0.18478994071483612, validation loss=0.1821564882993698, c=0.7038982582250484, ibs=0.1571414248607218, ibnll=0.47681102880148735\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 44, train loss=0.1876380741596222, validation loss=0.18294931948184967, c=0.7033760329309127, ibs=0.16378932814431657, ibnll=0.4924994669425257\n",
      "Validation loss decreased (0.182156 --> 0.181423).  Saving model ...                   \n",
      "it: 45, train loss=0.13843175768852234, validation loss=0.18142274022102356, c=0.7026387736921328, ibs=0.1543713027686981, ibnll=0.4719819396367161\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 46, train loss=0.16229677200317383, validation loss=0.18308626115322113, c=0.7016557613737597, ibs=0.16056929206125264, ibnll=0.48548449899828733\n",
      "Validation loss decreased (0.181423 --> 0.168252).  Saving model ...                   \n",
      "it: 47, train loss=0.19254149496555328, validation loss=0.16825155913829803, c=0.7056185297822013, ibs=0.15747414047414376, ibnll=0.47761766316950727\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 48, train loss=0.1633003205060959, validation loss=0.16915364563465118, c=0.7015636039689123, ibs=0.15793941813887113, ibnll=0.4794116612353665\n",
      "Validation loss decreased (0.168252 --> 0.165573).  Saving model ...                   \n",
      "it: 49, train loss=0.1592782586812973, validation loss=0.16557279229164124, c=0.6989217583632845, ibs=0.15531482094808244, ibnll=0.4725210636698\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 50, train loss=0.1627827137708664, validation loss=0.17368513345718384, c=0.6960341596780635, ibs=0.161208966036306, ibnll=0.4870187361766318\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 51, train loss=0.1662842333316803, validation loss=0.16901426017284393, c=0.701532884833963, ibs=0.15420597962827484, ibnll=0.46877684411874504\n",
      "EarlyStopping counter: 3 out of 20                                                     \n",
      "it: 52, train loss=0.16543428599834442, validation loss=0.1888156235218048, c=0.6983073756643013, ibs=0.16621812553299833, ibnll=0.49843608430589736\n",
      "EarlyStopping counter: 4 out of 20                                                     \n",
      "it: 53, train loss=0.20978203415870667, validation loss=0.16948169469833374, c=0.7014407274291156, ibs=0.15449178311067824, ibnll=0.4702263351634874\n",
      "EarlyStopping counter: 5 out of 20                                                     \n",
      "it: 54, train loss=0.17337481677532196, validation loss=0.1877119094133377, c=0.7024544588824378, ibs=0.16673084522943693, ibnll=0.500409994707724\n",
      "EarlyStopping counter: 6 out of 20                                                     \n",
      "it: 55, train loss=0.15783262252807617, validation loss=0.1729540228843689, c=0.7048812705434215, ibs=0.15453768144926325, ibnll=0.4703811809547326\n",
      "Validation loss decreased (0.165573 --> 0.164446).  Saving model ...                   \n",
      "it: 56, train loss=0.15154065191745758, validation loss=0.16444553434848785, c=0.7041747304395908, ibs=0.1542265891167117, ibnll=0.4696752772059592\n",
      "Validation loss decreased (0.164446 --> 0.158466).  Saving model ...                   \n",
      "it: 57, train loss=0.12746550142765045, validation loss=0.1584664136171341, c=0.7021472675329463, ibs=0.15737525681941014, ibnll=0.4770054342710017\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 58, train loss=0.13239909708499908, validation loss=0.17201459407806396, c=0.700764906460234, ibs=0.16333054618272586, ibnll=0.4911541912375261\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 59, train loss=0.15070131421089172, validation loss=0.16916018724441528, c=0.7011028169446748, ibs=0.16157252466250013, ibnll=0.48694714924333715\n",
      "EarlyStopping counter: 3 out of 20                                                     \n",
      "it: 60, train loss=0.11287599802017212, validation loss=0.1586425006389618, c=0.7009185021349799, ibs=0.15699149145070207, ibnll=0.4757455770204958\n",
      "Validation loss decreased (0.158466 --> 0.156788).  Saving model ...                   \n",
      "it: 61, train loss=0.17117688059806824, validation loss=0.15678797662258148, c=0.7002119620311492, ibs=0.15495270659200838, ibnll=0.4707558733138211\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 62, train loss=0.09570576995611191, validation loss=0.15719358623027802, c=0.6990753540380303, ibs=0.15515148865046216, ibnll=0.4714041400884937\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 63, train loss=0.14722803235054016, validation loss=0.15915854275226593, c=0.6980001843148097, ibs=0.15659536476949468, ibnll=0.4751069147350459\n",
      "EarlyStopping counter: 3 out of 20                                                     \n",
      "it: 64, train loss=0.14029185473918915, validation loss=0.1625443696975708, c=0.6977237121002673, ibs=0.1584093762497982, ibnll=0.4793761238607127\n",
      "EarlyStopping counter: 4 out of 20                                                     \n",
      "it: 65, train loss=0.17028562724590302, validation loss=0.16224229335784912, c=0.6982152182594538, ibs=0.15831387404759767, ibnll=0.47887461339398923\n",
      "EarlyStopping counter: 5 out of 20                                                     \n",
      "it: 66, train loss=0.11526541411876678, validation loss=0.15808404982089996, c=0.6999047706816576, ibs=0.15629664779906488, ibnll=0.47365504975511813\n",
      "Validation loss decreased (0.156788 --> 0.156727).  Saving model ...                   \n",
      "it: 67, train loss=0.11130314320325851, validation loss=0.15672685205936432, c=0.6998740515467085, ibs=0.15541294705781888, ibnll=0.47135788458377087\n",
      "Validation loss decreased (0.156727 --> 0.156424).  Saving model ...                   \n",
      "it: 68, train loss=0.09082698822021484, validation loss=0.1564239114522934, c=0.6990753540380303, ibs=0.15550719228080134, ibnll=0.4716628461603207\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 69, train loss=0.12862786650657654, validation loss=0.15776139497756958, c=0.698829600958437, ibs=0.15627999811297996, ibnll=0.47367953969882837\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 70, train loss=0.1624390333890915, validation loss=0.1587626188993454, c=0.6987374435535896, ibs=0.15677554500949642, ibnll=0.47493236318452714\n",
      "EarlyStopping counter: 3 out of 20                                                     \n",
      "it: 71, train loss=0.12771464884281158, validation loss=0.1583060771226883, c=0.6980923417196572, ibs=0.1567197338519815, ibnll=0.47481274213412583\n",
      "EarlyStopping counter: 4 out of 20                                                     \n",
      "it: 72, train loss=0.1346019208431244, validation loss=0.15800100564956665, c=0.6982766565293521, ibs=0.1567442078922214, ibnll=0.47473427311858674\n",
      "EarlyStopping counter: 5 out of 20                                                     \n",
      "it: 73, train loss=0.11940591782331467, validation loss=0.1583167463541031, c=0.6979080269099622, ibs=0.15692200415692054, ibnll=0.47512074099770113\n",
      "EarlyStopping counter: 6 out of 20                                                     \n",
      "it: 74, train loss=0.12178704887628555, validation loss=0.15763920545578003, c=0.6976008355604706, ibs=0.15653029320401218, ibnll=0.4741126816029805\n",
      "EarlyStopping counter: 7 out of 20                                                     \n",
      "it: 75, train loss=0.11036179959774017, validation loss=0.15761324763298035, c=0.6976008355604706, ibs=0.1565132396554359, ibnll=0.4740850220057955\n",
      "EarlyStopping counter: 8 out of 20                                                     \n",
      "it: 76, train loss=0.15946009755134583, validation loss=0.15762080252170563, c=0.6976315546954198, ibs=0.15651179828923795, ibnll=0.474086712941016\n",
      "EarlyStopping counter: 9 out of 20                                                     \n",
      "it: 77, train loss=0.17106281220912933, validation loss=0.1577729880809784, c=0.6976315546954198, ibs=0.15657988205736778, ibnll=0.47425940287841645\n",
      "EarlyStopping counter: 10 out of 20                                                    \n",
      "it: 78, train loss=0.13185669481754303, validation loss=0.15785644948482513, c=0.6975393972905723, ibs=0.15660805570788916, ibnll=0.47434460490253677\n",
      "EarlyStopping counter: 11 out of 20                                                    \n",
      "it: 79, train loss=0.1495194286108017, validation loss=0.15791817009449005, c=0.6975086781556231, ibs=0.15662802776354134, ibnll=0.4744003263935081\n",
      "EarlyStopping counter: 12 out of 20                                                    \n",
      "it: 80, train loss=0.13931486010551453, validation loss=0.15800940990447998, c=0.6973858016158265, ibs=0.1566549286216492, ibnll=0.47447973480354966\n",
      "EarlyStopping counter: 13 out of 20                                                    \n",
      "it: 81, train loss=0.1461571753025055, validation loss=0.15802304446697235, c=0.6973858016158265, ibs=0.15665975322797385, ibnll=0.47449220567045924\n",
      "EarlyStopping counter: 14 out of 20                                                    \n",
      "it: 82, train loss=0.11539100855588913, validation loss=0.15803757309913635, c=0.6973858016158265, ibs=0.1566668845292484, ibnll=0.4745096773985066\n",
      "EarlyStopping counter: 15 out of 20                                                    \n",
      "it: 83, train loss=0.11616948246955872, validation loss=0.1580539345741272, c=0.6973858016158265, ibs=0.1566750739145534, ibnll=0.47453008721901213\n",
      "EarlyStopping counter: 16 out of 20                                                    \n",
      "it: 84, train loss=0.1629490703344345, validation loss=0.15806393325328827, c=0.6973243633459282, ibs=0.1566785561901423, ibnll=0.47453994207094313\n",
      "EarlyStopping counter: 17 out of 20                                                    \n",
      "it: 85, train loss=0.12538199126720428, validation loss=0.15807461738586426, c=0.6973550824808773, ibs=0.15668279260298384, ibnll=0.4745514712782017\n",
      "EarlyStopping counter: 18 out of 20                                                    \n",
      "it: 86, train loss=0.11976590007543564, validation loss=0.15809835493564606, c=0.6973858016158265, ibs=0.15669330502730996, ibnll=0.4745776520514688\n",
      "EarlyStopping counter: 19 out of 20                                                    \n",
      "it: 87, train loss=0.1336774080991745, validation loss=0.1580987125635147, c=0.6973858016158265, ibs=0.1566933774946243, ibnll=0.4745777898850384\n",
      "EarlyStopping counter: 20 out of 20                                                    \n",
      "it: 88, train loss=0.12580431997776031, validation loss=0.15809889137744904, c=0.6973858016158265, ibs=0.15669346727196465, ibnll=0.47457803816842087\n",
      "Early stopping                                                                         \n",
      "  2%|         | 2/100 [47:38<37:39:33, 1383.41s/trial, best loss: 0.15809889137744904]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27005d16c14042b0a8ce67077b3153f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.463742).  Saving model ...                        \n",
      "it: 0, train loss=0.43851351737976074, validation loss=0.4637424647808075, c=0.5331164896839823, ibs=0.2406132245347525, ibnll=0.6665694489603302\n",
      "Validation loss decreased (0.463742 --> 0.454377).  Saving model ...                   \n",
      "it: 1, train loss=0.45083343982696533, validation loss=0.4543765187263489, c=0.5512293121591888, ibs=0.23701892737913066, ibnll=0.6585858546660246\n",
      "Validation loss decreased (0.454377 --> 0.444936).  Saving model ...                   \n",
      "it: 2, train loss=0.43320485949516296, validation loss=0.44493597745895386, c=0.5149080008928856, ibs=0.23333273038368618, ibnll=0.6504667775079991\n",
      "Validation loss decreased (0.444936 --> 0.435389).  Saving model ...                   \n",
      "it: 3, train loss=0.4173411428928375, validation loss=0.43538936972618103, c=0.4908957556044517, ibs=0.229558528239417, ibnll=0.642215920684109\n",
      "Validation loss decreased (0.435389 --> 0.425885).  Saving model ...                   \n",
      "it: 4, train loss=0.4233907461166382, validation loss=0.4258849620819092, c=0.5377084728467106, ibs=0.22573984134351904, ibnll=0.6339293950407906\n",
      "Validation loss decreased (0.425885 --> 0.416433).  Saving model ...                   \n",
      "it: 5, train loss=0.40199849009513855, validation loss=0.41643261909484863, c=0.4684460601422239, ibs=0.2218844243691333, ibnll=0.6256213970178904\n",
      "Validation loss decreased (0.416433 --> 0.407158).  Saving model ...                   \n",
      "it: 6, train loss=0.40038686990737915, validation loss=0.4071580171585083, c=0.5909627220255748, ibs=0.2180676803408788, ibnll=0.6174478922879068\n",
      "Validation loss decreased (0.407158 --> 0.398136).  Saving model ...                   \n",
      "it: 7, train loss=0.3756272494792938, validation loss=0.3981361389160156, c=0.5589145062023662, ibs=0.21429841114340875, ibnll=0.6094212458231651\n",
      "Validation loss decreased (0.398136 --> 0.389428).  Saving model ...                   \n",
      "it: 8, train loss=0.38062286376953125, validation loss=0.38942819833755493, c=0.5312669409101055, ibs=0.21061868422476576, ibnll=0.6016282651140714\n",
      "Validation loss decreased (0.389428 --> 0.381114).  Saving model ...                   \n",
      "it: 9, train loss=0.3736970126628876, validation loss=0.3811136484146118, c=0.41375681622500715, ibs=0.20706271487335656, ibnll=0.5941262801822803\n",
      "Validation loss decreased (0.381114 --> 0.373438).  Saving model ...                   \n",
      "it: 10, train loss=0.34466204047203064, validation loss=0.37343764305114746, c=0.5232628591472942, ibs=0.2037623829475506, ibnll=0.5871747740437862\n",
      "Validation loss decreased (0.373438 --> 0.366194).  Saving model ...                   \n",
      "it: 11, train loss=0.3403134346008301, validation loss=0.3661935031414032, c=0.561912050766925, ibs=0.20062572979089477, ibnll=0.5805754557864631\n",
      "Validation loss decreased (0.366194 --> 0.359637).  Saving model ...                   \n",
      "it: 12, train loss=0.3482179045677185, validation loss=0.359636515378952, c=0.6003699097547753, ibs=0.19772029064971464, ibnll=0.5744808977410358\n",
      "Validation loss decreased (0.359637 --> 0.353666).  Saving model ...                   \n",
      "it: 13, train loss=0.3380419611930847, validation loss=0.35366567969322205, c=0.5390478012691732, ibs=0.1950661836620966, ibnll=0.56890204752858\n",
      "Validation loss decreased (0.353666 --> 0.348216).  Saving model ...                   \n",
      "it: 14, train loss=0.3427118957042694, validation loss=0.3482162654399872, c=0.6072259957269046, ibs=0.1926520375746059, ibnll=0.5638139795125982\n",
      "Validation loss decreased (0.348216 --> 0.343468).  Saving model ...                   \n",
      "it: 15, train loss=0.3142334818840027, validation loss=0.3434678614139557, c=0.5716700149877229, ibs=0.19047733346445983, ibnll=0.5592254729701764\n",
      "Validation loss decreased (0.343468 --> 0.339188).  Saving model ...                   \n",
      "it: 16, train loss=0.33821678161621094, validation loss=0.3391878008842468, c=0.537899805478491, ibs=0.18851785307663396, ibnll=0.5550704076106173\n",
      "Validation loss decreased (0.339188 --> 0.335488).  Saving model ...                   \n",
      "it: 17, train loss=0.31786584854125977, validation loss=0.3354882299900055, c=0.6114034248541089, ibs=0.18680038250631673, ibnll=0.5514089556757675\n",
      "Validation loss decreased (0.335488 --> 0.332489).  Saving model ...                   \n",
      "it: 18, train loss=0.32026350498199463, validation loss=0.33248910307884216, c=0.5562358493574412, ibs=0.18528229379944736, ibnll=0.548163176655901\n",
      "Validation loss decreased (0.332489 --> 0.329774).  Saving model ...                   \n",
      "it: 19, train loss=0.30102524161338806, validation loss=0.32977381348609924, c=0.5984884722089352, ibs=0.18397583385657243, ibnll=0.5453462906494932\n",
      "Validation loss decreased (0.329774 --> 0.327300).  Saving model ...                   \n",
      "it: 20, train loss=0.28889501094818115, validation loss=0.327299565076828, c=0.639911986989381, ibs=0.1828499098545997, ibnll=0.5429024140918915\n",
      "Validation loss decreased (0.327300 --> 0.325646).  Saving model ...                   \n",
      "it: 21, train loss=0.31325116753578186, validation loss=0.32564646005630493, c=0.47035938646002745, ibs=0.18183461273213353, ibnll=0.540682444980208\n",
      "Validation loss decreased (0.325646 --> 0.324070).  Saving model ...                   \n",
      "it: 22, train loss=0.30962055921554565, validation loss=0.3240700960159302, c=0.4736439299722568, ibs=0.18098469970185707, ibnll=0.5388074289379148\n",
      "Validation loss decreased (0.324070 --> 0.322653).  Saving model ...                   \n",
      "it: 23, train loss=0.28473079204559326, validation loss=0.3226529359817505, c=0.6050575592333939, ibs=0.18024504178667558, ibnll=0.5371572014440413\n",
      "Validation loss decreased (0.322653 --> 0.321550).  Saving model ...                   \n",
      "it: 24, train loss=0.2735551595687866, validation loss=0.32154974341392517, c=0.5643355974361427, ibs=0.17962742856938685, ibnll=0.5357684888053185\n",
      "Validation loss decreased (0.321550 --> 0.320765).  Saving model ...                   \n",
      "it: 25, train loss=0.29978805780410767, validation loss=0.3207651972770691, c=0.47093338435536847, ibs=0.17911644498957274, ibnll=0.5346078399140726\n",
      "Validation loss decreased (0.320765 --> 0.319979).  Saving model ...                   \n",
      "it: 26, train loss=0.3015350103378296, validation loss=0.31997886300086975, c=0.568831914282981, ibs=0.17865216662835892, ibnll=0.5335399256528937\n",
      "Validation loss decreased (0.319979 --> 0.319414).  Saving model ...                   \n",
      "it: 27, train loss=0.28298044204711914, validation loss=0.3194143772125244, c=0.6231703817086004, ibs=0.17826963357473766, ibnll=0.5326494842618561\n",
      "Validation loss decreased (0.319414 --> 0.318996).  Saving model ...                   \n",
      "it: 28, train loss=0.27483904361724854, validation loss=0.3189956247806549, c=0.6249880417105137, ibs=0.17796391635849146, ibnll=0.5319304786091352\n",
      "Validation loss decreased (0.318996 --> 0.318732).  Saving model ...                   \n",
      "it: 29, train loss=0.2675148546695709, validation loss=0.3187318444252014, c=0.5982014732612647, ibs=0.17771419552987372, ibnll=0.5313294553907809\n",
      "Validation loss decreased (0.318732 --> 0.318528).  Saving model ...                   \n",
      "it: 30, train loss=0.29488489031791687, validation loss=0.3185283839702606, c=0.5938964890462068, ibs=0.17749992280078594, ibnll=0.5308091668167098\n",
      "Validation loss decreased (0.318528 --> 0.318185).  Saving model ...                   \n",
      "it: 31, train loss=0.26381996273994446, validation loss=0.3181852400302887, c=0.6423674224305622, ibs=0.17726954830148542, ibnll=0.5302563335165897\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 32, train loss=0.29698294401168823, validation loss=0.3182961642742157, c=0.5828629739468733, ibs=0.17717921729941633, ibnll=0.5300140229717264\n",
      "Validation loss decreased (0.318185 --> 0.318066).  Saving model ...                   \n",
      "it: 33, train loss=0.3031757175922394, validation loss=0.3180655837059021, c=0.5993175802799834, ibs=0.17701680445991397, ibnll=0.52961099728899\n",
      "EarlyStopping counter: 1 out of 20                                                     \n",
      "it: 34, train loss=0.27384722232818604, validation loss=0.3180765211582184, c=0.6141458592429605, ibs=0.17693494816357475, ibnll=0.5294037540134124\n",
      "EarlyStopping counter: 2 out of 20                                                     \n",
      "it: 35, train loss=0.3014522194862366, validation loss=0.31812548637390137, c=0.5517076437386397, ibs=0.17688776899040026, ibnll=0.529260538704195\n",
      "Validation loss decreased (0.318066 --> 0.317855).  Saving model ...                   \n",
      "it: 36, train loss=0.29827597737312317, validation loss=0.31785547733306885, c=0.6345865620714947, ibs=0.17683796250126874, ibnll=0.5291606843804235\n",
      "Validation loss decreased (0.317855 --> 0.317733).  Saving model ...                     \n",
      "it: 37, train loss=0.2795916199684143, validation loss=0.31773293018341064, c=0.6099684301157562, ibs=0.17668109753232214, ibnll=0.5287743133243618\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 38, train loss=0.27258312702178955, validation loss=0.3177645206451416, c=0.6335342325967027, ibs=0.1766325963218953, ibnll=0.52863547208895\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 39, train loss=0.2633800506591797, validation loss=0.3179584741592407, c=0.6217991645141746, ibs=0.1766205617124336, ibnll=0.5285691008470457\n",
      "Validation loss decreased (0.317733 --> 0.317440).  Saving model ...                     \n",
      "it: 40, train loss=0.2940341532230377, validation loss=0.31744012236595154, c=0.6308236869798144, ibs=0.1764465335216504, ibnll=0.5281586577588587\n",
      "Validation loss decreased (0.317440 --> 0.317287).  Saving model ...                     \n",
      "it: 41, train loss=0.2725788950920105, validation loss=0.317286878824234, c=0.6120093115214134, ibs=0.17638436697040452, ibnll=0.528004224772409\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 42, train loss=0.3020450174808502, validation loss=0.31753304600715637, c=0.6088523230970375, ibs=0.17641557606632025, ibnll=0.5280529142855851\n",
      "Validation loss decreased (0.317287 --> 0.316957).  Saving model ...                     \n",
      "it: 43, train loss=0.2710992693901062, validation loss=0.3169570863246918, c=0.614751745910265, ibs=0.1761916905308118, ibnll=0.5275458733064693\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 44, train loss=0.2525780498981476, validation loss=0.3174075186252594, c=0.6198858381963711, ibs=0.17636069446388983, ibnll=0.5279194791175602\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 45, train loss=0.27365174889564514, validation loss=0.3183664381504059, c=0.48059568226027616, ibs=0.17650354027998025, ibnll=0.5281955257204995\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 46, train loss=0.287500262260437, validation loss=0.3169925808906555, c=0.6123281992410472, ibs=0.17618697125237945, ibnll=0.5274880985380133\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 47, train loss=0.29390573501586914, validation loss=0.3169836103916168, c=0.6190567301253229, ibs=0.1761687109741823, ibnll=0.527462803471532\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 48, train loss=0.29037967324256897, validation loss=0.31737610697746277, c=0.580152428329985, ibs=0.17623777201341104, ibnll=0.5275657473360942\n",
      "Validation loss decreased (0.316957 --> 0.316460).  Saving model ...                     \n",
      "it: 49, train loss=0.2705720067024231, validation loss=0.31646016240119934, c=0.6053445581810645, ibs=0.176011681010977, ibnll=0.5270782308267553\n",
      "Validation loss decreased (0.316460 --> 0.316418).  Saving model ...                     \n",
      "it: 50, train loss=0.2639421224594116, validation loss=0.3164176940917969, c=0.6015816830893842, ibs=0.17597705147233816, ibnll=0.5270601911888172\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 51, train loss=0.2605326473712921, validation loss=0.3171873986721039, c=0.5953633725565228, ibs=0.17615526338459936, ibnll=0.5273741940210551\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 52, train loss=0.3083359897136688, validation loss=0.31700238585472107, c=0.5794827641187538, ibs=0.176132537398601, ibnll=0.5273105384928541\n",
      "Validation loss decreased (0.316418 --> 0.316265).  Saving model ...                     \n",
      "it: 53, train loss=0.2661888003349304, validation loss=0.3162652850151062, c=0.6025064574763226, ibs=0.17594741211083592, ibnll=0.5269956597250235\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 54, train loss=0.2479907125234604, validation loss=0.3170311748981476, c=0.5093912433432188, ibs=0.17611701360345278, ibnll=0.5272705233461912\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 55, train loss=0.284464955329895, validation loss=0.31859275698661804, c=0.37902994355687364, ibs=0.1764502328525677, ibnll=0.5280012353770765\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 56, train loss=0.29389098286628723, validation loss=0.3166705071926117, c=0.5894320609713319, ibs=0.1760431190685898, ibnll=0.5271897086802017\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 57, train loss=0.29877129197120667, validation loss=0.3168499767780304, c=0.5384419146018686, ibs=0.17602296443394505, ibnll=0.5270631862631121\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 58, train loss=0.2821464240550995, validation loss=0.31679078936576843, c=0.6267100353965369, ibs=0.1760270129516793, ibnll=0.5271425174231902\n",
      "Validation loss decreased (0.316265 --> 0.315935).  Saving model ...                     \n",
      "it: 59, train loss=0.2988986074924469, validation loss=0.31593480706214905, c=0.611499091169999, ibs=0.17598297143563302, ibnll=0.527124775074957\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 60, train loss=0.28387001156806946, validation loss=0.3159577250480652, c=0.6100003188877197, ibs=0.17600442872061686, ibnll=0.5271973077888449\n",
      "Validation loss decreased (0.315935 --> 0.315579).  Saving model ...                     \n",
      "it: 61, train loss=0.2811112105846405, validation loss=0.31557944416999817, c=0.6342357855798973, ibs=0.17597172723329177, ibnll=0.5271328077669103\n",
      "Validation loss decreased (0.315579 --> 0.315208).  Saving model ...                     \n",
      "it: 62, train loss=0.27977848052978516, validation loss=0.3152076303958893, c=0.6227877164450397, ibs=0.17608829985676688, ibnll=0.5274791554825865\n",
      "Validation loss decreased (0.315208 --> 0.314761).  Saving model ...                     \n",
      "it: 63, train loss=0.31332826614379883, validation loss=0.3147607445716858, c=0.6251155967983673, ibs=0.17581596788848686, ibnll=0.5268603275625448\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 64, train loss=0.3085421025753021, validation loss=0.31617245078086853, c=0.5780796581523645, ibs=0.17617944146546913, ibnll=0.5275509668668722\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 65, train loss=0.29362034797668457, validation loss=0.3159075081348419, c=0.6192799515290666, ibs=0.17603275103349006, ibnll=0.527221751288485\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 66, train loss=0.29759037494659424, validation loss=0.31615450978279114, c=0.587231735705858, ibs=0.17602170762316047, ibnll=0.5271352755433234\n",
      "Validation loss decreased (0.314761 --> 0.314045).  Saving model ...                     \n",
      "it: 67, train loss=0.27590879797935486, validation loss=0.314044713973999, c=0.6179725118785676, ibs=0.1756145282732034, ibnll=0.5263502426782941\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 68, train loss=0.25895828008651733, validation loss=0.31452322006225586, c=0.6192799515290666, ibs=0.17562915958183195, ibnll=0.5263761439922338\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 69, train loss=0.2767696678638458, validation loss=0.316829651594162, c=0.5413119040785739, ibs=0.17622401465750345, ibnll=0.5275704850018431\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 70, train loss=0.2936318516731262, validation loss=0.3157891631126404, c=0.6314933511910457, ibs=0.1759878670999206, ibnll=0.5271170995539289\n",
      "Validation loss decreased (0.314045 --> 0.313400).  Saving model ...                     \n",
      "it: 71, train loss=0.2833290994167328, validation loss=0.31340041756629944, c=0.6217034981982844, ibs=0.17530800594356638, ibnll=0.5255884055527644\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 72, train loss=0.25789904594421387, validation loss=0.31354230642318726, c=0.6151025224018623, ibs=0.17530399813139658, ibnll=0.5256436887620479\n",
      "Validation loss decreased (0.313400 --> 0.310244).  Saving model ...                     \n",
      "it: 73, train loss=0.2907903492450714, validation loss=0.31024444103240967, c=0.6236806020600146, ibs=0.17453372997921776, ibnll=0.5239036265408432\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 74, train loss=0.27878352999687195, validation loss=0.31091752648353577, c=0.6241589336394655, ibs=0.1747137021395952, ibnll=0.5242654329660299\n",
      "Validation loss decreased (0.310244 --> 0.308990).  Saving model ...                     \n",
      "it: 75, train loss=0.2655668556690216, validation loss=0.3089900612831116, c=0.632577569437801, ibs=0.17402847351425926, ibnll=0.5226835022319893\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 76, train loss=0.2771812379360199, validation loss=0.3094532787799835, c=0.6185146210019452, ibs=0.1742905949379623, ibnll=0.5232181130409972\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 77, train loss=0.3212115466594696, validation loss=0.31178051233291626, c=0.619471284160847, ibs=0.17483059773844029, ibnll=0.5243934503017251\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 78, train loss=0.2640376091003418, validation loss=0.31241288781166077, c=0.6213846104786505, ibs=0.17505622716917904, ibnll=0.5247631584970985\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 79, train loss=0.2723774015903473, validation loss=0.3097960352897644, c=0.6195988392487005, ibs=0.17428745526031755, ibnll=0.5231616871853281\n",
      "Validation loss decreased (0.308990 --> 0.308515).  Saving model ...                     \n",
      "it: 80, train loss=0.2845119833946228, validation loss=0.3085152804851532, c=0.6238400459198317, ibs=0.17423556214427663, ibnll=0.5233927378109298\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 81, train loss=0.24926385283470154, validation loss=0.3110121786594391, c=0.5904843904461239, ibs=0.17454184460644803, ibnll=0.5235954652785855\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 82, train loss=0.29333657026290894, validation loss=0.31136757135391235, c=0.609617653624159, ibs=0.17493052966817405, ibnll=0.5246321807286873\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 83, train loss=0.31621184945106506, validation loss=0.30995094776153564, c=0.6268694792563538, ibs=0.17458387308474085, ibnll=0.5238848071843865\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 84, train loss=0.29117563366889954, validation loss=0.31049129366874695, c=0.614592302050448, ibs=0.174655924367824, ibnll=0.5239301614305006\n",
      "Validation loss decreased (0.308515 --> 0.304703).  Saving model ...                     \n",
      "it: 85, train loss=0.26251500844955444, validation loss=0.3047026991844177, c=0.6260403711853056, ibs=0.17327207162860395, ibnll=0.521184550276825\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 86, train loss=0.257922500371933, validation loss=0.31016433238983154, c=0.6326732357536912, ibs=0.17497295518083328, ibnll=0.5250471652978846\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 87, train loss=0.2628892660140991, validation loss=0.30608493089675903, c=0.6237762683759048, ibs=0.17345881433153768, ibnll=0.5212613032632698\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 88, train loss=0.2482943832874298, validation loss=0.3087488114833832, c=0.6159954080168373, ibs=0.17435600070218552, ibnll=0.5233324515624063\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 89, train loss=0.2537074387073517, validation loss=0.3093756437301636, c=0.6064606651997831, ibs=0.1745577953478896, ibnll=0.5235330719691292\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 90, train loss=0.27487924695014954, validation loss=0.30701982975006104, c=0.6159954080168373, ibs=0.17392268994445484, ibnll=0.5223715332320502\n",
      "Validation loss decreased (0.304703 --> 0.302268).  Saving model ...                     \n",
      "it: 91, train loss=0.28050336241722107, validation loss=0.30226776003837585, c=0.6261679262731592, ibs=0.1725892571791773, ibnll=0.5193843952346847\n",
      "Validation loss decreased (0.302268 --> 0.301405).  Saving model ...                     \n",
      "it: 92, train loss=0.2556648850440979, validation loss=0.3014048933982849, c=0.620204725916005, ibs=0.17218258067806103, ibnll=0.5182709279316198\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 93, train loss=0.28445199131965637, validation loss=0.3018382787704468, c=0.6288784718900475, ibs=0.17226457224130814, ibnll=0.5185216968082057\n",
      "Validation loss decreased (0.301405 --> 0.300841).  Saving model ...                     \n",
      "it: 94, train loss=0.24556764960289001, validation loss=0.3008406162261963, c=0.6290379157498645, ibs=0.17217857113339086, ibnll=0.5181895953859432\n",
      "Validation loss decreased (0.300841 --> 0.300555).  Saving model ...                     \n",
      "it: 95, train loss=0.2862815260887146, validation loss=0.3005545735359192, c=0.6270927006600976, ibs=0.17200732683309386, ibnll=0.5179545290420816\n",
      "Validation loss decreased (0.300555 --> 0.298002).  Saving model ...                     \n",
      "it: 96, train loss=0.27344635128974915, validation loss=0.29800179600715637, c=0.6266143690806467, ibs=0.17164662735953676, ibnll=0.517074784063012\n",
      "Validation loss decreased (0.298002 --> 0.293656).  Saving model ...                     \n",
      "it: 97, train loss=0.28105780482292175, validation loss=0.29365551471710205, c=0.6292930259255716, ibs=0.17062414119580346, ibnll=0.5149772485169456\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 98, train loss=0.2432207465171814, validation loss=0.29994943737983704, c=0.6203322810038585, ibs=0.1718012499003059, ibnll=0.5171231326409893\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 99, train loss=0.2779121994972229, validation loss=0.30387070775032043, c=0.6218629420581013, ibs=0.1725134991590934, ibnll=0.5187433633004456\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 100, train loss=0.26793310046195984, validation loss=0.2983391284942627, c=0.6266781466245734, ibs=0.17135130572602955, ibnll=0.5165245829378892\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 101, train loss=0.29520729184150696, validation loss=0.29764261841773987, c=0.6199177269683345, ibs=0.17134894740456008, ibnll=0.5162516230106512\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 102, train loss=0.28330767154693604, validation loss=0.29749295115470886, c=0.6241589336394655, ibs=0.1716372195703457, ibnll=0.517087016782426\n",
      "Validation loss decreased (0.293656 --> 0.291943).  Saving model ...                     \n",
      "it: 103, train loss=0.27813267707824707, validation loss=0.29194268584251404, c=0.6268694792563538, ibs=0.17054269266116479, ibnll=0.5147866418303098\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 104, train loss=0.2450665384531021, validation loss=0.2951675355434418, c=0.6252750406581843, ibs=0.17101939470689126, ibnll=0.515594955014444\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 105, train loss=0.2676425576210022, validation loss=0.2947773337364197, c=0.6276666985554387, ibs=0.1706833279897652, ibnll=0.5146202976473964\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 106, train loss=0.252873957157135, validation loss=0.2943766713142395, c=0.6262635925890494, ibs=0.1706864894402812, ibnll=0.5144239154529726\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 107, train loss=0.24498873949050903, validation loss=0.2956576347351074, c=0.6243183774992825, ibs=0.17084438950352326, ibnll=0.5148749930992588\n",
      "Validation loss decreased (0.291943 --> 0.287817).  Saving model ...                     \n",
      "it: 108, train loss=0.2684610188007355, validation loss=0.2878165543079376, c=0.6297394687330591, ibs=0.16911890811132155, ibnll=0.5110782917054486\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 109, train loss=0.2674339711666107, validation loss=0.2919222414493561, c=0.6290698045218278, ibs=0.16994768732775128, ibnll=0.5128765407148488\n",
      "Validation loss decreased (0.287817 --> 0.287773).  Saving model ...                     \n",
      "it: 110, train loss=0.2157810479402542, validation loss=0.2877725660800934, c=0.626965145572244, ibs=0.16892349462579428, ibnll=0.5106800903472337\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 111, train loss=0.2767985165119171, validation loss=0.2881694436073303, c=0.6246691539908799, ibs=0.1694247386769169, ibnll=0.5118202420195904\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 112, train loss=0.2231498807668686, validation loss=0.2966080605983734, c=0.6219904971459549, ibs=0.17147784417459355, ibnll=0.5164633278946041\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 113, train loss=0.2274990677833557, validation loss=0.29622867703437805, c=0.6259447048694154, ibs=0.17140512526523077, ibnll=0.5162356708638453\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 114, train loss=0.27888697385787964, validation loss=0.29152166843414307, c=0.6223093848655888, ibs=0.17057825511926808, ibnll=0.5141129115277167\n",
      "Validation loss decreased (0.287773 --> 0.286532).  Saving model ...                     \n",
      "it: 115, train loss=0.25391319394111633, validation loss=0.2865319550037384, c=0.6337574540004465, ibs=0.16922162826981188, ibnll=0.511338999021605\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 116, train loss=0.26206567883491516, validation loss=0.2894015312194824, c=0.6231066041646737, ibs=0.16937924348431174, ibnll=0.5111696104510818\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 117, train loss=0.27326470613479614, validation loss=0.29464253783226013, c=0.6237124908319781, ibs=0.17082139828564266, ibnll=0.5144611401476684\n",
      "Validation loss decreased (0.286532 --> 0.283934).  Saving model ...                     \n",
      "it: 118, train loss=0.23147544264793396, validation loss=0.2839336693286896, c=0.629484358557352, ibs=0.1684174203763835, ibnll=0.5094424725783633\n",
      "Validation loss decreased (0.283934 --> 0.277314).  Saving model ...                     \n",
      "it: 119, train loss=0.24614593386650085, validation loss=0.27731385827064514, c=0.6367231097930419, ibs=0.16714735374413958, ibnll=0.5065442458946696\n",
      "Validation loss decreased (0.277314 --> 0.276926).  Saving model ...                     \n",
      "it: 120, train loss=0.25844085216522217, validation loss=0.2769264280796051, c=0.6397844319015275, ibs=0.16717868610689024, ibnll=0.5065377175713486\n",
      "Validation loss decreased (0.276926 --> 0.274692).  Saving model ...                     \n",
      "it: 121, train loss=0.2649284899234772, validation loss=0.274692177772522, c=0.6381581045313945, ibs=0.16678445296851221, ibnll=0.5056564899853225\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 122, train loss=0.3040209114551544, validation loss=0.28050386905670166, c=0.6308555757517778, ibs=0.168043762281799, ibnll=0.5078434670659943\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 123, train loss=0.2471894472837448, validation loss=0.28026431798934937, c=0.6247648203067699, ibs=0.16759456586681715, ibnll=0.506869075234844\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 124, train loss=0.2587023973464966, validation loss=0.2766108512878418, c=0.6278899199591824, ibs=0.16663463088145433, ibnll=0.5045710209411701\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 125, train loss=0.24655459821224213, validation loss=0.2757870554924011, c=0.6320354603144233, ibs=0.16637363290628396, ibnll=0.5040953067144871\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 126, train loss=0.21880632638931274, validation loss=0.2790989875793457, c=0.6286871392582671, ibs=0.16735420460860953, ibnll=0.5060031456440136\n",
      "EarlyStopping counter: 6 out of 20                                                       \n",
      "it: 127, train loss=0.30428457260131836, validation loss=0.2842445969581604, c=0.6242227111833923, ibs=0.16817910938413244, ibnll=0.5077205340942381\n",
      "EarlyStopping counter: 7 out of 20                                                       \n",
      "it: 128, train loss=0.22516146302223206, validation loss=0.28237372636795044, c=0.6279855862750725, ibs=0.16788151072056115, ibnll=0.5071162039496785\n",
      "EarlyStopping counter: 8 out of 20                                                       \n",
      "it: 129, train loss=0.23155146837234497, validation loss=0.2785034477710724, c=0.6307280206639242, ibs=0.16717796575392133, ibnll=0.5054925359198588\n",
      "Validation loss decreased (0.274692 --> 0.274368).  Saving model ...                     \n",
      "it: 130, train loss=0.2961764931678772, validation loss=0.27436766028404236, c=0.6360534455818107, ibs=0.1663914707817889, ibnll=0.503600447121493\n",
      "Validation loss decreased (0.274368 --> 0.271451).  Saving model ...                     \n",
      "it: 131, train loss=0.2579091787338257, validation loss=0.27145129442214966, c=0.6367231097930419, ibs=0.16588572296970872, ibnll=0.502479114891008\n",
      "Validation loss decreased (0.271451 --> 0.270856).  Saving model ...                     \n",
      "it: 132, train loss=0.24956628680229187, validation loss=0.2708556354045868, c=0.6357983354061035, ibs=0.16570274481408506, ibnll=0.5021087912853562\n",
      "Validation loss decreased (0.270856 --> 0.268396).  Saving model ...                     \n",
      "it: 133, train loss=0.2494884729385376, validation loss=0.26839619874954224, c=0.6373927740042731, ibs=0.16535866730356202, ibnll=0.5014073725828024\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 134, train loss=0.24375967681407928, validation loss=0.26855969429016113, c=0.6387321024267355, ibs=0.16515200888518058, ibnll=0.500970860524649\n",
      "Validation loss decreased (0.268396 --> 0.268005).  Saving model ...                     \n",
      "it: 135, train loss=0.27482104301452637, validation loss=0.2680053114891052, c=0.6395612104977837, ibs=0.1649652668572975, ibnll=0.5005666968714974\n",
      "Validation loss decreased (0.268005 --> 0.266136).  Saving model ...                     \n",
      "it: 136, train loss=0.21490515768527985, validation loss=0.26613613963127136, c=0.6407092062884658, ibs=0.16468073686774892, ibnll=0.4999678743947472\n",
      "Validation loss decreased (0.266136 --> 0.265647).  Saving model ...                     \n",
      "it: 137, train loss=0.22188186645507812, validation loss=0.2656472623348236, c=0.640804872604356, ibs=0.16466676368197347, ibnll=0.49996057569399255\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 138, train loss=0.2305455207824707, validation loss=0.267703652381897, c=0.6409962052361363, ibs=0.165008645051061, ibnll=0.5006662479621227\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 139, train loss=0.28293463587760925, validation loss=0.267631471157074, c=0.6397206543576007, ibs=0.165039452567077, ibnll=0.5006738450198103\n",
      "Validation loss decreased (0.265647 --> 0.265636).  Saving model ...                     \n",
      "it: 140, train loss=0.21968813240528107, validation loss=0.2656361162662506, c=0.6394655441818936, ibs=0.16474105898881397, ibnll=0.5000218312078161\n",
      "Validation loss decreased (0.265636 --> 0.265352).  Saving model ...                     \n",
      "it: 141, train loss=0.2439536303281784, validation loss=0.26535162329673767, c=0.6398163206734908, ibs=0.16469009709544774, ibnll=0.4998863742189627\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 142, train loss=0.24517473578453064, validation loss=0.26547878980636597, c=0.6401670971650881, ibs=0.16469803198847882, ibnll=0.4998673144350736\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 143, train loss=0.23941339552402496, validation loss=0.26560622453689575, c=0.6408367613763194, ibs=0.16468391088586307, ibnll=0.4998084258935248\n",
      "Validation loss decreased (0.265352 --> 0.264448).  Saving model ...                     \n",
      "it: 144, train loss=0.2233756184577942, validation loss=0.264448344707489, c=0.6409324276922096, ibs=0.16451085140545887, ibnll=0.499457406961348\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 145, train loss=0.24392694234848022, validation loss=0.264543354511261, c=0.6419528683950381, ibs=0.16451271487722605, ibnll=0.49942077498230847\n",
      "Validation loss decreased (0.264448 --> 0.263502).  Saving model ...                     \n",
      "it: 146, train loss=0.21646647155284882, validation loss=0.2635018229484558, c=0.6427500876941229, ibs=0.16437472048470164, ibnll=0.4991347176941582\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 147, train loss=0.22306190431118011, validation loss=0.2637162208557129, c=0.6426544213782327, ibs=0.1644281465649467, ibnll=0.4992096868125164\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 148, train loss=0.23195555806159973, validation loss=0.26490718126296997, c=0.6426544213782327, ibs=0.1645585126517739, ibnll=0.49944934441591915\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 149, train loss=0.22515705227851868, validation loss=0.2643929123878479, c=0.6420166459389649, ibs=0.1644625161157589, ibnll=0.49924244690732733\n",
      "Validation loss decreased (0.263502 --> 0.263252).  Saving model ...                     \n",
      "it: 150, train loss=0.2346058487892151, validation loss=0.26325228810310364, c=0.643324085589464, ibs=0.16430353148666282, ibnll=0.4989085222427087\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 151, train loss=0.25111836194992065, validation loss=0.26339980959892273, c=0.643164641729647, ibs=0.16430136743498114, ibnll=0.49886938621108673\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 152, train loss=0.20956194400787354, validation loss=0.26354578137397766, c=0.6423993112025256, ibs=0.16434450004581624, ibnll=0.49892162666971646\n",
      "Validation loss decreased (0.263252 --> 0.262734).  Saving model ...                     \n",
      "it: 153, train loss=0.23308271169662476, validation loss=0.262733519077301, c=0.6422079785707452, ibs=0.16422579727924794, ibnll=0.4986809572287783\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 154, train loss=0.2525496780872345, validation loss=0.263090580701828, c=0.6426863101501961, ibs=0.16426399312537504, ibnll=0.49875259167931096\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 155, train loss=0.23670415580272675, validation loss=0.2637946307659149, c=0.6426225326062693, ibs=0.16435667263572784, ibnll=0.4989368018745979\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 156, train loss=0.20556338131427765, validation loss=0.2631479501724243, c=0.6427181989221595, ibs=0.16428171069498004, ibnll=0.4987794402063296\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 157, train loss=0.23105928301811218, validation loss=0.2637385129928589, c=0.6416339806754042, ibs=0.16436315840800533, ibnll=0.4988982958997742\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 158, train loss=0.27441856265068054, validation loss=0.26298627257347107, c=0.6411237603239899, ibs=0.1642725690618172, ibnll=0.49868986931582093\n",
      "Validation loss decreased (0.262734 --> 0.261787).  Saving model ...                     \n",
      "it: 159, train loss=0.26268985867500305, validation loss=0.26178672909736633, c=0.6417296469912943, ibs=0.16407335467629147, ibnll=0.49831544239624775\n",
      "Validation loss decreased (0.261787 --> 0.261750).  Saving model ...                     \n",
      "it: 160, train loss=0.22409668564796448, validation loss=0.26174989342689514, c=0.6427500876941229, ibs=0.16405741804307392, ibnll=0.49825546398668125\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 161, train loss=0.2415936291217804, validation loss=0.26375770568847656, c=0.6424311999744889, ibs=0.16433882601809163, ibnll=0.4987893781922675\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 162, train loss=0.2568894028663635, validation loss=0.263119637966156, c=0.6427819764660863, ibs=0.16425943567942713, ibnll=0.49859648085188774\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 163, train loss=0.2469506561756134, validation loss=0.26187029480934143, c=0.6437067508530246, ibs=0.16406952314272902, ibnll=0.49819837230182323\n",
      "Validation loss decreased (0.261750 --> 0.260740).  Saving model ...                     \n",
      "it: 164, train loss=0.24036800861358643, validation loss=0.2607404589653015, c=0.6431008641857202, ibs=0.16389154183233268, ibnll=0.4978449642423007\n",
      "Validation loss decreased (0.260740 --> 0.260309).  Saving model ...                     \n",
      "it: 165, train loss=0.19573378562927246, validation loss=0.2603089511394501, c=0.64479096909978, ibs=0.1638040512103944, ibnll=0.4976830136935559\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 166, train loss=0.2195732444524765, validation loss=0.2611598074436188, c=0.6440256385726586, ibs=0.16389099938815216, ibnll=0.49782409605361266\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 167, train loss=0.22279256582260132, validation loss=0.2611258924007416, c=0.6441850824324755, ibs=0.16390057545403605, ibnll=0.49782870857241535\n",
      "Validation loss decreased (0.260309 --> 0.259742).  Saving model ...                     \n",
      "it: 168, train loss=0.22466234862804413, validation loss=0.2597416937351227, c=0.6453011894511942, ibs=0.163715585592424, ibnll=0.4974788267436787\n",
      "Validation loss decreased (0.259742 --> 0.259574).  Saving model ...                     \n",
      "it: 169, train loss=0.22523044049739838, validation loss=0.25957420468330383, c=0.6455562996269014, ibs=0.16369555529391863, ibnll=0.49743030944578265\n",
      "Validation loss decreased (0.259574 --> 0.259251).  Saving model ...                     \n",
      "it: 170, train loss=0.2207687944173813, validation loss=0.2592506408691406, c=0.6443126375203291, ibs=0.16363894788511082, ibnll=0.49724963349253865\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 171, train loss=0.24407604336738586, validation loss=0.2604885995388031, c=0.643738639624988, ibs=0.16382668666511563, ibnll=0.497582255554298\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 172, train loss=0.2608795166015625, validation loss=0.26006609201431274, c=0.6435473069932077, ibs=0.1637991621947055, ibnll=0.4975265348748178\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 173, train loss=0.22432105243206024, validation loss=0.2593390941619873, c=0.6440894161165853, ibs=0.16367682230421418, ibnll=0.4973010633280632\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 174, train loss=0.23905307054519653, validation loss=0.25943565368652344, c=0.6434516406773175, ibs=0.16368437203299704, ibnll=0.49730091353190636\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 175, train loss=0.26861172914505005, validation loss=0.2603611946105957, c=0.6421442010268185, ibs=0.16381822105315536, ibnll=0.4975441328282685\n",
      "EarlyStopping counter: 6 out of 20                                                       \n",
      "it: 176, train loss=0.26150453090667725, validation loss=0.2603090703487396, c=0.6423674224305622, ibs=0.16385860788091233, ibnll=0.49759922470703244\n",
      "EarlyStopping counter: 7 out of 20                                                       \n",
      "it: 177, train loss=0.2592250406742096, validation loss=0.26012417674064636, c=0.6427181989221595, ibs=0.16383219646329933, ibnll=0.4975461029864848\n",
      "EarlyStopping counter: 8 out of 20                                                       \n",
      "it: 178, train loss=0.22187823057174683, validation loss=0.2598769962787628, c=0.6429414203259033, ibs=0.16379688619391378, ibnll=0.4974764808375642\n",
      "EarlyStopping counter: 9 out of 20                                                       \n",
      "it: 179, train loss=0.224094420671463, validation loss=0.2594965994358063, c=0.6434835294492809, ibs=0.16374383844239002, ibnll=0.49737109177138117\n",
      "Validation loss decreased (0.259251 --> 0.259250).  Saving model ...                     \n",
      "it: 180, train loss=0.2444179505109787, validation loss=0.2592504620552063, c=0.6439937498006951, ibs=0.16370662717926504, ibnll=0.4972981506940129\n",
      "Validation loss decreased (0.259250 --> 0.259111).  Saving model ...                     \n",
      "it: 181, train loss=0.22800132632255554, validation loss=0.259110689163208, c=0.6439299722567684, ibs=0.1636833125578588, ibnll=0.4972515801580722\n",
      "Validation loss decreased (0.259111 --> 0.259042).  Saving model ...                     \n",
      "it: 182, train loss=0.22321347892284393, validation loss=0.25904151797294617, c=0.6440894161165853, ibs=0.1636704405433524, ibnll=0.4972259632963936\n",
      "Validation loss decreased (0.259042 --> 0.258956).  Saving model ...                     \n",
      "it: 183, train loss=0.18791238963603973, validation loss=0.25895556807518005, c=0.644057527344622, ibs=0.16365802437665333, ibnll=0.4972014230690744\n",
      "EarlyStopping counter: 1 out of 20                                                       \n",
      "it: 184, train loss=0.1948370784521103, validation loss=0.259042888879776, c=0.644057527344622, ibs=0.163666333529973, ibnll=0.49721411964896955\n",
      "EarlyStopping counter: 2 out of 20                                                       \n",
      "it: 185, train loss=0.24066731333732605, validation loss=0.2592030167579651, c=0.6441531936605122, ibs=0.16368489275012688, ibnll=0.49724513812286275\n",
      "EarlyStopping counter: 3 out of 20                                                       \n",
      "it: 186, train loss=0.2685694992542267, validation loss=0.2593550682067871, c=0.643738639624988, ibs=0.16370467290401058, ibnll=0.49727740179267765\n",
      "EarlyStopping counter: 4 out of 20                                                       \n",
      "it: 187, train loss=0.23520462214946747, validation loss=0.25940534472465515, c=0.6437067508530246, ibs=0.16371033321559744, ibnll=0.49728540391873055\n",
      "EarlyStopping counter: 5 out of 20                                                       \n",
      "it: 188, train loss=0.2666684091091156, validation loss=0.25950467586517334, c=0.6436429733090979, ibs=0.16372393679656672, ibnll=0.4973077470772152\n",
      "EarlyStopping counter: 6 out of 20                                                       \n",
      "it: 189, train loss=0.24136321246623993, validation loss=0.2595048248767853, c=0.6436110845371344, ibs=0.1637220448689507, ibnll=0.49730166446449947\n",
      "EarlyStopping counter: 7 out of 20                                                       \n",
      "it: 190, train loss=0.22198446094989777, validation loss=0.25949352979660034, c=0.6436110845371344, ibs=0.16372041946093338, ibnll=0.4972984289066102\n",
      "  2%|         | 2/100 [1:52:18<37:39:33, 1383.41s/trial, best loss: 0.15809889137744904]"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "args = {\n",
    "    \"lr\": hp.choice(\"lr\", [1e-4, 5e-4]),\n",
    "    \"weight_decay\": hp.choice(\"weight_decay\", [1e-3, 1e-4]),\n",
    "    \"num_latent\": hp.randint('num_latent', 20, 400),\n",
    "    \"encoder_neurons\": hp.randint('encoder_neurons', 100, 800),\n",
    "    \"num_encoder_layers\": hp.randint(\"num_encoder_layers\", 2, 5),\n",
    "    \"encoder_dropout\": 0.,\n",
    "    \"odefunc_neurons1\": hp.randint('odefunc_neurons1', 100, 1500),\n",
    "    \"num_odefunc_layers1\": hp.randint(\"num_encoder_layers1\", 2, 5),\n",
    "    \"odefunc_neurons2\": hp.randint('odefunc_neurons2', 100, 1500),\n",
    "    \"num_odefunc_layers2\": 3,\n",
    "    \"batch_size\": 1/3,\n",
    "    \"multiplier\": 1.,\n",
    "    \"mu\": 1e-4,\n",
    "    \"softplus_beta\": 1.,\n",
    "    \"scheduler_epoch\": 5,\n",
    "    \"scheduler_gamma\": 0.1,\n",
    "    \"patience\": 20\n",
    "}\n",
    "\n",
    "# define an objective function\n",
    "def objective(args):\n",
    "    lossval, conc, ibs, ibnll = odesurv_manual_benchmark(df_train,df_test,args,\"metabrick_test\")\n",
    "    return lossval\n",
    "\n",
    "# define a search space\n",
    "\n",
    "# minimize the objective over the space\n",
    "from hyperopt import fmin, tpe, space_eval\n",
    "best = fmin(objective, args, algo=tpe.suggest, max_evals=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best)\n",
    "print(space_eval(space, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
